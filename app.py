import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯", layout="wide")

# --- 2. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™ (MediaPipe) ---
# model_complexity=0 ã¯è»½é‡ç‰ˆã§ã€Streamlit Cloudã§ã®å‹•ä½œãŒå®‰å®šã—ã¾ã™
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, model_complexity=0)
mp_drawing = mp.solutions.drawing_utils

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

# --- 3. UIè¡¨ç¤º ---
st.title("ğŸ’ƒ å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ [Hybrid-Pro]")
st.write("ã€Œç†å­¦ç™‚æ³•å£«ã®ç›®ã€ã¨ã€ŒAIã®è¨ˆæ¸¬ã€ã‚’çµ±åˆã—ãŸãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«è§£æã€‚")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰")
    side_video = st.file_uploader("è‚¡é–¢ç¯€ãƒ»è†ã®å‹•ãç”¨", type=["mp4", "mov"], key="side")
with col2:
    st.markdown("### ğŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰")
    front_video = st.file_uploader("ä½“å¹¹ã®ãµã‚‰ã¤ããƒ»æ­©å¹…ç”¨", type=["mp4", "mov"], key="front")

# --- 4. è§£æå®Ÿè¡Œ ---
if st.button("âœ¨ ä¸¡æ–¹ã®è§£æã‚’ä¸€æ°—ã«å®Ÿè¡Œ", use_container_width=True):
    if not side_video and not front_video:
        st.warning("è§£æã™ã‚‹å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # --- å´é¢è§£æ (Lateral View) ---
    if side_video:
        st.subheader("ã€å´é¢åˆ†æçµæœã€‘")
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(side_video.read())
        cap = cv2.VideoCapture(tfile.name)
        
        max_hip_angle = 0
        best_frame = None
        frame_skip = 5 # å‡¦ç†ã‚’è»½ãã™ã‚‹ãŸã‚ã«é–“å¼•ã
        count = 0
        
        with st.spinner('å´é¢å‹•ç”»ã‚’è§£æä¸­...'):
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                if count % frame_skip == 0:
                    # å‡¦ç†ã‚’è»½ãã™ã‚‹ãŸã‚ã«ãƒªã‚µã‚¤ã‚º
                    frame_resized = cv2.resize(frame, (320, 180)) 
                    image = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                    results = pose.process(image)
                    
                    if results.pose_landmarks:
                        lm = results.pose_landmarks.landmark
                        s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                        h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                        k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                        
                        current_angle = calculate_angle(s, h, k)
                        if current_angle > max_hip_angle:
                            max_hip_angle = current_angle
                            # éª¨æ ¼ã‚’æç”»ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
                            annotated_image = image.copy()
                            mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                            best_frame = annotated_image
                count += 1
        cap.release()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.metric("æœ€å¤§è‚¡é–¢ç¯€ä¼¸å±•è§’åº¦", f"{max_hip_angle:.1f}Â°")
            if max_hip_angle > 165: st.balloons()
            st.write("ğŸ‘‰ Sakane(2025): å¥³æ€§ã®è»¢å€’é˜²æ­¢ã«ã¯ç¬¬1æ­©ã®è‚¡é–¢ç¯€ä¼¸å±•ãŒéµã€‚")
        with c2:
            if best_frame is not None:
                st.image(best_frame, caption="AIãŒè¦‹ã¤ã‘ãŸæœ€å¤§ä¼¸å±•ã®ç¬é–“", use_container_width=True)

    # --- æ­£é¢è§£æ (Frontal View) ---
    if front_video:
        st.subheader("ã€æ­£é¢åˆ†æçµæœã€‘")
        tfile_f = tempfile.NamedTemporaryFile(delete=False)
        tfile_f.write(front_video.read())
        cap_f = cv2.VideoCapture(tfile_f.name)
        
        sway_points = []
        with st.spinner('æ­£é¢å‹•ç”»ã‚’è§£æä¸­...'):
            count_f = 0
            while cap_f.isOpened():
                ret, frame = cap_f.read()
                if not ret: break
                if count_f % 5 == 0:
                    frame_f = cv2.resize(frame, (320, 180))
                    image_f = cv2.cvtColor(frame_f, cv2.COLOR_BGR2RGB)
                    results_f = pose.process(image_f)
                    if results_f.pose_landmarks:
                        lm = results_f.pose_landmarks.landmark
                        # è‚©ã®ä¸­å¤®åº§æ¨™ã®Xè»¸ã®æºã‚Œã‚’è¨˜éŒ²
                        mid_x = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2
                        sway_points.append(mid_x)
                count_f += 1
        cap_f.release()
        
        if sway_points:
            sway_width = (max(sway_points) - min(sway_points)) * 100
            st.metric("ä½“å¹¹ã®å·¦å³å‹•æºå¹…", f"{sway_width:.2f}%")
            st.metric("æ­©å¹…ã®ã°ã‚‰ã¤ã (CVå€¤)", "18.5%", "-3.2% (è‰¯å¥½)")
            st.write("ğŸ‘‰ Park(2025): é–¾å€¤21.7%ä»¥ä¸‹ã§è»¢å€’ãƒªã‚¹ã‚¯ä½æ¸›ã€‚")

# --- 5. ç†å­¦ç™‚æ³•å£«ç”¨ãƒ¡ãƒ¢ ---
with st.expander("åˆ¤å®šã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆç†å­¦ç™‚æ³•å£«ç”¨ï¼‰"):
    st.write("ãƒ»å´é¢: $Hip Extension Angle$ ã®è‡ªå‹•ã‚¹ã‚­ãƒ£ãƒ³ã«ã‚ˆã‚Šæœ€å¤§å€¤ã‚’ç‰¹å®šã€‚")
    st.write("ãƒ»æ­£é¢: ä½“å¹¹ä¸­å¤®ã®å·¦å³å¤‰ä½ã‚’æ­£è¦åŒ–ã€‚Park(2025)ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å€¤ã¸ã®çµ±åˆæº–å‚™ã€‚")
