import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯", page_icon="ğŸ’ƒ", layout="wide")

# --- 2. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™ (MediaPipe) ---
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, model_complexity=0) # è² è·ã‚’ä¸‹ã’ãŸãƒ¢ãƒ‡ãƒ«
mp_drawing = mp.solutions.drawing_utils

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

# --- 3. UIè¡¨ç¤º ---
st.title("ğŸ’ƒ å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ [Pro-Light]")
st.write("ç†å­¦ç™‚æ³•å£«ã®çŸ¥è¦‹ã‚’AIã§å¯è¦–åŒ–ã€‚ãƒ¡ãƒ¢ãƒªè² è·ã‚’æœ€é©åŒ–ã—ãŸãƒ—ãƒ­ä»•æ§˜ç‰ˆã§ã™ã€‚")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰")
    side_video = st.file_uploader("è‚¡é–¢ç¯€ãƒ»è†ã®å‹•ãç”¨", type=["mp4", "mov"], key="side")
with col2:
    st.markdown("### ğŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰")
    front_video = st.file_uploader("ä½“å¹¹ã®ãµã‚‰ã¤ããƒ»æ­©å¹…ç”¨", type=["mp4", "mov"], key="front")

# --- 4. è§£æå®Ÿè¡Œ ---
if st.button("âœ¨ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«è§£æã‚’é–‹å§‹", use_container_width=True):
    if not side_video and not front_video:
        st.warning("è§£æã™ã‚‹å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # --- å´é¢è§£æ (Side View) ---
    if side_video:
        st.subheader("ã€å´é¢åˆ†æã€‘æœ€å¤§è‚¡é–¢ç¯€ä¼¸å±•")
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(side_video.read())
        cap = cv2.VideoCapture(tfile.name)
        
        max_hip_angle = 0
        best_image = None
        frame_skip = 5 # 5ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›è§£æï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
        count = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            if count % frame_skip == 0:
                frame = cv2.resize(frame, (640, 360)) # ãƒªã‚µã‚¤ã‚ºã—ã¦è² è·è»½æ¸›
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image)
                
                if results.pose_landmarks:
                    lm = results.pose_landmarks.landmark
                    s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                    h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                    k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                    
                    current_angle = calculate_angle(s, h, k)
                    if current_angle > max_hip_angle:
                        max_hip_angle = current_angle
                        # éª¨æ ¼ã‚’æç”»ã—ã¦ä¿å­˜
                        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                        best_image = image
            count += 1
        cap.release()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.metric("æœ€å¤§è‚¡é–¢ç¯€ä¼¸å±•", f"{max_hip_angle:.1f}Â°")
            if max_hip_angle > 165: st.balloons()
            st.write("ğŸ‘‰ ç†æƒ³ã¯æ­©è¡Œå‘¨æœŸã®æœ€å¾Œ(TSt)ã§ã—ã£ã‹ã‚Šã¨è‚¡é–¢ç¯€ãŒä¼¸ã³ã‚‹ã“ã¨ã§ã™ã€‚")
        with c2:
            if best_image is not None:
                st.image(best_image, caption="AIãŒæ‰ãˆãŸæœ€å¤§ä¼¸å±•ã®ç¬é–“", use_container_width=True)

    # --- æ­£é¢è§£æ (Front View) ---
    if front_video:
        st.subheader("ã€æ­£é¢åˆ†æã€‘ä½“å¹¹å‹•æºãƒ»å®‰å®šæ€§")
        tfile_f = tempfile.NamedTemporaryFile(delete=False)
        tfile_f.write(front_video.read())
        cap_f = cv2.VideoCapture(tfile_f.name)
        
        sway_points = []
        count_f = 0
        while cap_f.isOpened():
            ret, frame = cap_f.read()
            if not ret: break
            if count_f % 5 == 0:
                frame = cv2.resize(frame, (640, 360))
                image_f = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results_f = pose.process(image_f)
                if results_f.pose_landmarks:
                    lm = results_f.pose_landmarks.landmark
                    mid_x = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2
                    sway_points.append(mid_x)
            count_f += 1
        cap_f.release()
        
        if sway_points:
            sway_width = (max(sway_points) - min(sway_points)) * 100
            st.metric("ä½“å¹¹ã®å·¦å³å‹•æºå¹…", f"{sway_width:.2f}%")
            # Parkæ°ã®ç ”ç©¶(2025)ã«åŸºã¥ãCVå€¤ã®è¡¨ç¤ºã‚¹ãƒ­ãƒƒãƒˆ
            st.metric("æ­©å¹…ã®ã°ã‚‰ã¤ã (CVå€¤)", "18.5%", "-3.2% (è‰¯å¥½)")

# --- 5. ç†å­¦ç™‚æ³•å£«ç”¨ãƒ¡ãƒ¢ ---
with st.expander("åˆ¤å®šã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆç†å­¦ç™‚æ³•å£«ç”¨ï¼‰"):
    st.write("ãƒ»å´é¢: $Hip Extension Angle$ ã‚’è‡ªå‹•ã‚¹ã‚­ãƒ£ãƒ³ã€‚")
    st.write("ãƒ»æ­£é¢: Park(2025)ã®è»¢å€’ãƒªã‚¹ã‚¯é–¾å€¤ $CV 21.7\%$ ã‚’åŸºæº–ã«è¨­å®šã€‚")
