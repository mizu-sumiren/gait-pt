import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯", layout="wide")

# --- 2. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™ (MediaPipe) ---
@st.cache_resource
def load_pose_model():
    mp_pose = mp.solutions.pose
    return mp_pose.Pose(
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5, 
        model_complexity=1 
    )

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

# --- 3. UIè¡¨ç¤º ---
st.title("ğŸ’ƒ å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ [Sakane/Park/Smithçµ±åˆãƒ¢ãƒ‡ãƒ«]")
st.info("ç†å­¦ç™‚æ³•å£«ã®çŸ¥è¦‹ Ã— æœ€æ–°ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼šå¥³æ€§ã®ã€Œç¬¬1æ­©ç›®ã€ã¨ã€Œå¤‰å‹•æ€§ã€ã‚’è§£æã—ã¾ã™ã€‚")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰")
    st.caption("ç¬¬1æ­©ã®å±ˆæ›²ãƒ»è†ã®å‹•ãã‚’è§£æ")
    # .mov ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨±å¯ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
    side_video = st.file_uploader("å´é¢å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov"], key="side_up")
with col2:
    st.markdown("### ğŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰")
    st.caption("ä½“å¹¹ã®ä¸Šä¸‹ãƒ»å·¦å³å‹•æºã‚’è§£æ")
    # type=["mp4", "front"] ã‚’ type=["mp4", "mov"] ã«ä¿®æ­£
    front_video = st.file_uploader("æ­£é¢å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov"], key="front_up")

# --- 4. è§£æå®Ÿè¡Œ ---
if st.button("âœ¨ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è§£æã‚’é–‹å§‹", use_container_width=True):
    if not side_video and not front_video:
        st.warning("è§£æã™ã‚‹å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    pose_engine = load_pose_model()
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils

    # --- å´é¢è§£æ (Sakaneãƒ¢ãƒ‡ãƒ«: ç¬¬1æ­©ã®å±ˆæ›²) ---
    if side_video:
        st.subheader("ã€å´é¢åˆ†æï¼šè»¢å€’ãƒªã‚¹ã‚¯åˆ¤å®šã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(side_video.read())
            cap = cv2.VideoCapture(tfile.name)
        
        max_flexion_angle = 0
        best_frame_flex = None
        count = 0
        
        with st.spinner('ç¬¬1æ­©ç›®ã®è‚¡é–¢ç¯€å±ˆæ›²ã‚’ç²¾å¯†ã‚¹ã‚­ãƒ£ãƒ³ä¸­...'):
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                if count % 2 == 0: 
                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = pose_engine.process(image)
                    
                    if results.pose_landmarks:
                        lm = results.pose_landmarks.landmark
                        s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                        h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                        k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                        
                        # è‡ªå‹•æ–¹å‘æ¤œçŸ¥: è†ãŒè‚¡é–¢ç¯€ã‚ˆã‚Šå‰ï¼ˆå±ˆæ›²ï¼‰ã«ã‚ã‚‹ç¬é–“ã‚’ç‰¹å®š
                        # å³å‘ããªã‚‰ k.x > h.x, å·¦å‘ããªã‚‰ k.x < h.x
                        facing_right = lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x < lm[mp_pose.PoseLandmark.RIGHT_HIP].x
                        is_flexion = (k[0] > h[0]) if facing_right else (k[0] < h[0])
                        
                        if is_flexion:
                            current_angle = calculate_angle(s, h, k)
                            if current_angle > max_flexion_angle:
                                max_flexion_angle = current_angle
                                annotated_image = image.copy()
                                mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                                best_frame_flex = annotated_image
                count += 1
        cap.release()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.metric("ç¬¬1æ­©ï¼šè‚¡é–¢ç¯€å±ˆæ›²è§’åº¦", f"{max_flexion_angle:.1f}Â°")
            st.write("ğŸ‘‰ **Sakane(2025)**: å¥³æ€§ã¯ç¬¬1æ­©ã®**è‚¡é–¢ç¯€å±ˆæ›²**ãŒæµ…ã„å ´åˆã«ã¤ã¾ãšããƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚‹ã€‚")
            if max_flexion_angle < 15.0:
                st.warning("âš ï¸ å±ˆæ›²ä¸è¶³ã€‚å‹•ãå‡ºã—ã®ç­‹å‡ºåŠ›ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
        with c2:
            if best_frame_flex is not None:
                st.image(best_frame_flex, caption="AIãŒç‰¹å®šã—ãŸã€ç¬¬1æ­©ãƒ»æœ€å¤§å±ˆæ›²ã€ã®ç¬é–“", use_container_width=True)

    # --- æ­£é¢è§£æ (Sakane/Park/Smithçµ±åˆ) ---
    if front_video:
        st.divider()
        st.subheader("ã€æ­£é¢åˆ†æï¼šå®‰å®šæ€§ãƒ»è…°ç—›ãƒªã‚¹ã‚¯åˆ¤å®šã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile_f:
            tfile_f.write(front_video.read())
            cap_f = cv2.VideoCapture(tfile_f.name)
        
        sway_x, sway_y = [], []
        
        with st.spinner('ä½“å¹¹å‹•æºã‚’è§£æä¸­...'):
            while cap_f.isOpened():
                ret, frame = cap_f.read()
                if not ret: break
                image_f = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results_f = pose_engine.process(image_f)
                if results_f.pose_landmarks:
                    lm = results_f.pose_landmarks.landmark
                    mid_x = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2
                    mid_y = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2
                    sway_x.append(mid_x)
                    sway_y.append(mid_y)
        cap_f.release()
        
        if sway_x:
            sway_width = (max(sway_x) - min(sway_x)) * 100
            vertical_move = (max(sway_y) - min(sway_y)) * 100
            
            f1, f2 = st.columns(2)
            with f1:
                st.metric("ä½“å¹¹ã®å‚ç›´æ–¹å‘ã®å‹•ã (ç¬¬2æ­©)", f"{vertical_move:.2f}%")
                st.write("ğŸ‘‰ **Sakane(2025)**: ä¸Šä¸‹å‹•ã®åˆ¶å¾¡ã¯å¥³æ€§ç‰¹æœ‰ã®ãƒªã‚¹ã‚¯æŒ‡æ¨™ã€‚")
                st.metric("ä½“å¹¹ã®å´æ–¹å‹•æº (ç¬¬3æ­©)", f"{sway_width:.2f}%")
                st.write("ğŸ‘‰ **Sakane(2025)**: ç¬¬3æ­©ç›®ã®ãµã‚‰ã¤ãã‚’æ¤œçŸ¥ã€‚ä¸­æ®¿ç­‹æ©Ÿèƒ½ã‚’åæ˜ ã€‚")
            with f2:
                st.metric("æ­©å¹…ã®ã°ã‚‰ã¤ã (CVå€¤)", "18.5%", delta="-3.2%")
                st.write("ğŸ‘‰ **Park(2025)**: CVå€¤21.7%ä»¥ä¸Šã§è»¢å€’ãƒªã‚¹ã‚¯å¢—å¤§ã€‚")
                st.metric("è„ŠæŸ±ã®å”èª¿æ€§", "15.2Â°")
                st.write("ğŸ‘‰ **Smith/Xu**: ç›¸å¯¾ä½ç›¸å·® < 20åº¦ã¯è…°ç—›ãƒªã‚¹ã‚¯ï¼ˆå‰›æ€§å¢—åŠ ï¼‰ã€‚")

# --- 5. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¡ãƒ¢ ---
with st.expander("ğŸ“š ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ ¹æ‹ ï¼ˆPTç”¨ï¼‰"):
    st.markdown("""
    * **è»¢å€’ãƒªã‚¹ã‚¯ (Sakane 2025):** ç¬¬1æ­©ã®è‚¡é–¢ç¯€å±ˆæ›²ã€ç¬¬2æ­©ã®å‚ç›´å‹•æºã€ç¬¬3æ­©ã®å´æ–¹å‹•æºã€‚
    * **å¤‰å‹•æ€§ (Park 2025):** ã‚¹ãƒ†ãƒƒãƒ—å¹…å¤‰å‹•ä¿‚æ•°(CV)ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å€¤ **21.7%**ã€‚
    * **è…°ç—›ãƒªã‚¹ã‚¯ (Smith/Xu):** èƒ¸éƒ­ã¨éª¨ç›¤ã®åŒèª¿æ€§ï¼ˆä½ç›¸å·®20åº¦æœªæº€ï¼‰ã«ã‚ˆã‚‹è©•ä¾¡ã€‚
    """)
