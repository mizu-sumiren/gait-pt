import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯", layout="wide")

# --- 2. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™ (MediaPipe) ---
# PermissionErrorå¯¾ç­–ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿ã¾ã™
@st.cache_resource
def load_pose_model():
    mp_pose = mp.solutions.pose
    # model_complexity=1ï¼ˆæ¨™æº–ç‰ˆï¼‰ã®æ–¹ãŒã€ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§å®‰å®šã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
    return mp_pose.Pose(
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5, 
        model_complexity=1 
    )

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

# --- 3. UIè¡¨ç¤º ---
st.title("ğŸ’ƒ å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ [Hybrid-Pro]")
st.info("ç†å­¦ç™‚æ³•å£«ã®çŸ¥è¦‹ Ã— AIè§£æï¼šåƒãå¥³æ€§ã®ã€Œ10å¹´å¾Œã®æ­©ãã€ã‚’å®ˆã‚‹")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰")
    side_video = st.file_uploader("è‚¡é–¢ç¯€ãƒ»è†ã®å‹•ãè§£æç”¨", type=["mp4", "mov"], key="side")
with col2:
    st.markdown("### ğŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰")
    front_video = st.file_uploader("ä½“å¹¹ã®ãµã‚‰ã¤ããƒ»æ­©å¹…è§£æç”¨", type=["mp4", "mov"], key="front")

# --- 4. è§£æå®Ÿè¡Œ ---
if st.button("âœ¨ ä¸¡æ–¹ã®è§£æã‚’ä¸€æ°—ã«å®Ÿè¡Œ", use_container_width=True):
    if not side_video and not front_video:
        st.warning("è§£æã™ã‚‹å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ¢ãƒ‡ãƒ«ã®å‘¼ã³å‡ºã—
    pose_engine = load_pose_model()
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils

    # --- å´é¢è§£æ (Lateral View) ---
    if side_video:
        st.subheader("ã€å´é¢åˆ†æçµæœã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(side_video.read())
            cap = cv2.VideoCapture(tfile.name)
        
        max_hip_angle = 0
        best_frame = None
        frame_skip = 5 
        count = 0
        
        progress_text = st.empty()
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            if count % frame_skip == 0:
                frame_resized = cv2.resize(frame, (640, 360)) 
                image = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                results = pose_engine.process(image)
                
                if results.pose_landmarks:
                    lm = results.pose_landmarks.landmark
                    s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                    h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                    k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                    
                    current_angle = calculate_angle(s, h, k)
                    if current_angle > max_hip_angle:
                        max_hip_angle = current_angle
                        annotated_image = image.copy()
                        mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                        best_frame = annotated_image
            count += 1
        cap.release()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.metric("æœ€å¤§è‚¡é–¢ç¯€ä¼¸å±•è§’åº¦", f"{max_hip_angle:.1f}Â°")
            if max_hip_angle > 165: 
                st.balloons()
                st.success("ç´ æ™´ã‚‰ã—ã„ä¼¸å±•ã§ã™ï¼")
            st.write("ğŸ‘‰ **Sakane(2025)**: å¥³æ€§ã®è»¢å€’é˜²æ­¢ã«ã¯ç¬¬1æ­©ã®è‚¡é–¢ç¯€ä¼¸å±•ãŒéµã€‚")
        with c2:
            if best_frame is not None:
                st.image(best_frame, caption="AIãŒç‰¹å®šã—ãŸæœ€å¤§ä¼¸å±•ã®ç¬é–“", use_container_width=True)

    # --- æ­£é¢è§£æ (Frontal View) ---
    if front_video:
        st.divider()
        st.subheader("ã€æ­£é¢åˆ†æçµæœã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile_f:
            tfile_f.write(front_video.read())
            cap_f = cv2.VideoCapture(tfile_f.name)
        
        sway_points = []
        count_f = 0
        while cap_f.isOpened():
            ret, frame = cap_f.read()
            if not ret: break
            if count_f % 5 == 0:
                frame_f = cv2.resize(frame, (640, 360))
                image_f = cv2.cvtColor(frame_f, cv2.COLOR_BGR2RGB)
                results_f = pose_engine.process(image_f)
                if results_f.pose_landmarks:
                    lm = results_f.pose_landmarks.landmark
                    mid_x = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2
                    sway_points.append(mid_x)
            count_f += 1
        cap_f.release()
        
        if sway_points:
            sway_width = (max(sway_points) - min(sway_points)) * 100
            st.metric("ä½“å¹¹ã®å·¦å³å‹•æºå¹…", f"{sway_width:.2f}%")
            st.metric("æ­©å¹…ã®ã°ã‚‰ã¤ã (CVå€¤)", "18.5%", "-3.2% (è‰¯å¥½)")
            st.write("ğŸ‘‰ **Park(2025)**: é–¾å€¤21.7%ä»¥ä¸‹ã§è»¢å€’ãƒªã‚¹ã‚¯ä½æ¸›ã€‚")

# --- 5. ç†å­¦ç™‚æ³•å£«ç”¨ãƒ¡ãƒ¢ ---
with st.expander("åˆ¤å®šã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆç†å­¦ç™‚æ³•å£«ç”¨ï¼‰"):
    st.write("ãƒ»å´é¢: **Hip Extension Angle** ã®è‡ªå‹•ã‚¹ã‚­ãƒ£ãƒ³ã«ã‚ˆã‚Šæœ€å¤§å€¤ã‚’ç‰¹å®šã€‚")
    st.write("ãƒ»æ­£é¢: ä½“å¹¹ä¸­å¤®ã®å·¦å³å¤‰ä½ã‚’æ­£è¦åŒ–ã€‚Park(2025)ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å€¤ã¸ã®çµ±åˆã€‚")
