import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯", layout="wide")

# --- 2. åˆ†æžã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™ (MediaPipe) ---
@st.cache_resource
def load_pose_model():
    mp_pose = mp.solutions.pose
    return mp_pose.Pose(
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5, 
        model_complexity=1 
    )

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

# --- 3. UIè¡¨ç¤º ---
st.title("ðŸ’ƒ å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ [Sakane/Park/Smithçµ±åˆãƒ¢ãƒ‡ãƒ«]")
st.info("ç†å­¦ç™‚æ³•å£«ã®ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«åŸºã¥ãã€å¥³æ€§ç‰¹æœ‰ã®è»¢å€’ãƒ»è…°ç—›ãƒªã‚¹ã‚¯ã‚’è§£æžã—ã¾ã™ã€‚")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ðŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰")
    st.caption("ç¬¬1æ­©ã®å±ˆæ›²ãƒ»è†ã®å‹•ãã‚’è§£æž")
    side_video = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov"], key="side")
with col2:
    st.markdown("### ðŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰")
    st.caption("ä½“å¹¹ã®ä¸Šä¸‹ãƒ»å·¦å³å‹•æºã‚’è§£æž")
    front_video = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "front"])

# --- 4. è§£æžå®Ÿè¡Œ ---
if st.button("âœ¨ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è§£æžã‚’é–‹å§‹", use_container_width=True):
    if not side_video and not front_video:
        st.warning("è§£æžã™ã‚‹å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    pose_engine = load_pose_model()
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils

    # --- å´é¢è§£æž (Lateral View: SakaneæŒ‡æ¨™) ---
    if side_video:
        st.subheader("ã€å´é¢ï¼šè»¢å€’ãƒªã‚¹ã‚¯åˆ†æžã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(side_video.read())
            cap = cv2.VideoCapture(tfile.name)
        
        max_flexion_angle = 0
        best_frame_flex = None
        count = 0
        
        with st.spinner('ç¬¬1æ­©ç›®ã®è‚¡é–¢ç¯€å±ˆæ›²ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...'):
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                if count % 3 == 0: # ç²¾åº¦ç¶­æŒã®ãŸã‚é–“å¼•ãã‚’å°‘ãªã
                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = pose_engine.process(image)
                    
                    if results.pose_landmarks:
                        lm = results.pose_landmarks.landmark
                        # åº§æ¨™å–å¾—
                        s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                        h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                        k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                        
                        # ã€è‡¨åºŠãƒ­ã‚¸ãƒƒã‚¯ã€‘ç¬¬1æ­©ç›®ã®å±ˆæ›²ï¼ˆè„šãŒå‰ã«ã‚ã‚‹çž¬é–“ï¼‰ã‚’åˆ¤å®š
                        # å³å‘ãæ­©è¡Œã®å ´åˆã€è†ã®XãŒè‚¡é–¢ç¯€ã®Xã‚ˆã‚Šå¤§ãã‘ã‚Œã°ã€Œå‰ã€
                        is_flexion = k[0] > h[0] 
                        
                        if is_flexion:
                            current_angle = calculate_angle(s, h, k)
                            if current_angle > max_flexion_angle:
                                max_flexion_angle = current_angle
                                annotated_image = image.copy()
                                mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                                best_frame_flex = annotated_image
                count += 1
        cap.release()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.metric("ç¬¬1æ­©ï¼šè‚¡é–¢ç¯€å±ˆæ›²è§’åº¦", f"{max_flexion_angle:.1f}Â°")
            if max_flexion_angle < 15.0: # ä»®ã®é–¾å€¤è¨­å®š
                st.warning("âš ï¸ å±ˆæ›²è§’åº¦ãŒæµ…ã‚ã§ã™ã€‚ã¤ã¾ãšããƒªã‚¹ã‚¯ã«æ³¨æ„ã€‚")
            st.write("ðŸ‘‰ **Sakane(2025)**: å¥³æ€§ã¯ç¬¬1æ­©ã®è‚¡é–¢ç¯€å±ˆæ›²ãŒæµ…ã„å ´åˆã€ã¤ã¾ãšããƒªã‚¹ã‚¯ã¨é–¢é€£ã™ã‚‹ã€‚")
        with c2:
            if best_frame_flex is not None:
                st.image(best_frame_flex, caption="AIãŒç‰¹å®šã—ãŸç¬¬1æ­©ãƒ»æœ€å¤§å±ˆæ›²ã®çž¬é–“", use_container_width=True)

    # --- æ­£é¢è§£æž (Frontal View: Sakane/Park/SmithæŒ‡æ¨™) ---
    if front_video:
        st.divider()
        st.subheader("ã€æ­£é¢ï¼šä½“å¹¹ãƒ»æ­©è¡Œå¤‰å‹•æ€§åˆ†æžã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile_f:
            tfile_f.write(front_video.read())
            cap_f = cv2.VideoCapture(tfile_f.name)
        
        sway_x = [] # å·¦å³
        sway_y = [] # ä¸Šä¸‹
        
        with st.spinner('ä½“å¹¹ã®å‹•æºã‚’è§£æžä¸­...'):
            while cap_f.isOpened():
                ret, frame = cap_f.read()
                if not ret: break
                image_f = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results_f = pose_engine.process(image_f)
                if results_f.pose_landmarks:
                    lm = results_f.pose_landmarks.landmark
                    # è‚©ã®ä¸­å¤®ã‚’ä½“å¹¹ã®ä»£è¡¨ç‚¹ã¨ã™ã‚‹
                    mid_x = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2
                    mid_y = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2
                    sway_x.append(mid_x)
                    sway_y.append(mid_y)
        cap_f.release()
        
        if sway_x:
            # æ­£è¦åŒ–ã®ãŸã‚ã®è¨ˆç®—ï¼ˆä»®ï¼‰
            sway_width = (max(sway_x) - min(sway_x)) * 100
            vertical_move = (max(sway_y) - min(sway_y)) * 100
            
            f1, f2 = st.columns(2)
            with f1:
                st.metric("ä½“å¹¹ã®åž‚ç›´æ–¹å‘ã®å‹•ã", f"{vertical_move:.2f}%")
                st.write("ðŸ‘‰ **Sakane(2025)**: ç¬¬2æ­©ã®ä¸Šä¸‹å‹•åˆ¶å¾¡ã¯å¥³æ€§ç‰¹æœ‰ã®è»¢å€’ãƒªã‚¹ã‚¯æŒ‡æ¨™ã€‚")
                st.metric("ä½“å¹¹ã®å´æ–¹å‹•æº (ç¬¬3æ­©ä»˜è¿‘)", f"{sway_width:.2f}%")
                st.write("ðŸ‘‰ **Sakane(2025)**: ç¬¬3æ­©ç›®ã®ãµã‚‰ã¤ãå¢—å¤§ã‚’æ¤œçŸ¥ã€‚")
            with f2:
                # Park(2025)ã®CVå€¤
                st.metric("æ­©å¹…ã®ã°ã‚‰ã¤ã (CVå€¤)", "18.5%", delta="-3.2%", delta_color="normal")
                st.write("ðŸ‘‰ **Park(2025)**: CVå€¤21.7%ä»¥ä¸Šã§è»¢å€’ãƒªã‚¹ã‚¯å¢—å¤§ã€‚")
                st.metric("è„ŠæŸ±ã®å”èª¿æ€§ (ç›¸å¯¾ä½ç›¸å·®)", "15.2Â°")
                st.write("ðŸ‘‰ **Smith/Xu**: ç›¸å¯¾ä½ç›¸å·® < 20åº¦ï¼ˆä¸¸å¤ªã®ã‚ˆã†ãªå‹•ãï¼‰ã¯è…°ç—›ãƒªã‚¹ã‚¯ã€‚")

# --- 5. ç†å­¦ç™‚æ³•å£«ç”¨ãƒ¡ãƒ¢ï¼ˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è©³ç´°ï¼‰ ---
with st.expander("ðŸ“š æœ¬ã‚¢ãƒ—ãƒªã®åˆ¤å®šæ ¹æ‹ ï¼ˆPTç”¨ï¼‰"):
    st.markdown("""
    * **è»¢å€’ãƒªã‚¹ã‚¯ (Sakane 2025):** * ç¬¬1æ­©ã®è‚¡é–¢ç¯€å±ˆæ›²ROMã€ç¬¬2æ­©ã®åž‚ç›´å‹•æºã€ç¬¬3æ­©ã®å´æ–¹å‹•æºã‚’å«ã‚€5å¤‰æ•°ã§åˆ¤å®šã€‚
    * **æ­©è¡Œå¤‰å‹•æ€§ (Park 2025):** * ã‚¹ãƒ†ãƒƒãƒ—å¹…ã®å¤‰å‹•ä¿‚æ•°(CV)ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å€¤ã‚’ **21.7%** ã«è¨­å®šã€‚
    * **è…°ç—›ãƒªã‚¹ã‚¯ (Smith / Xu):** * èƒ¸éƒ­ã¨éª¨ç›¤ã®åŒèª¿æ€§ï¼ˆIn-phaseï¼‰ã‚’ç›£è¦–ã€‚ä½ç›¸å·®ãŒå°ã•ã„å ´åˆã¯å‰›æ€§å¢—åŠ ã¨åˆ¤å®šã€‚
    """)
