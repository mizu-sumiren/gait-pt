import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import tempfile
import matplotlib.pyplot as plt
import japanize_matplotlib
import math

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ç·åˆæ­©è¡Œãƒ»èº«ä½“æ©Ÿèƒ½åˆ†æAI (Pro)", page_icon="ğŸ›¡ï¸", layout="wide")

st.title("ğŸ›¡ï¸ ç·åˆæ­©è¡Œãƒ»èº«ä½“æ©Ÿèƒ½åˆ†æAI (Pro)")
st.markdown("æ­©è¡Œã®ã€Œå·¦å³å·®ã€ã¨ã€Œæ©Ÿèƒ½ä¸å…¨ã€ã‚’å¾¹åº•çš„ã«åˆ†æã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè©³ç´°ãªæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯ ---
st.sidebar.header("ğŸ“‹ èº«ä½“æ©Ÿèƒ½ãƒ»æ¸¬å®šãƒ‡ãƒ¼ã‚¿")

with st.sidebar.expander("1. å•è¨ºãƒ»ç—›ã¿", expanded=True):
    pain_areas = st.multiselect(
        "ç—›ã¿ãƒ»é•å’Œæ„Ÿã®ã‚ã‚‹éƒ¨ä½",
        ["ç‰¹ã«ãªã—", "é¦–", "è‚©", "è…°", "è‚¡é–¢ç¯€(å³)", "è‚¡é–¢ç¯€(å·¦)", "è†(å³)", "è†(å·¦)", "è¶³é¦–ãƒ»è¶³éƒ¨"]
    )
    history = st.text_area("æ—¢å¾€æ­´ãƒ»ç‰¹è¨˜äº‹é …")

with st.sidebar.expander("2. æ©Ÿèƒ½æ¸¬å®šçµæœ", expanded=True):
    col_s1, col_s2 = st.columns(2)
    with col_s1:
        grip_l = st.number_input("æ¡åŠ›(å·¦) kg", value=20.0)
        hip_flex_l = st.number_input("è‚¡å±ˆæ›²(å·¦) kgf/kg", value=0.8)
        one_leg_l = st.number_input("ç‰‡è„šç«‹ä½(å·¦) ç§’", value=10)
        toe_grip_l = st.number_input("è¶³è¶¾æŠŠæŒ(å·¦) %", value=8.0)
    with col_s2:
        grip_r = st.number_input("æ¡åŠ›(å³) kg", value=29.0)
        hip_flex_r = st.number_input("è‚¡å±ˆæ›²(å³) kgf/kg", value=1.36)
        one_leg_r = st.number_input("ç‰‡è„šç«‹ä½(å³) ç§’", value=120)
        toe_grip_r = st.number_input("è¶³è¶¾æŠŠæŒ(å³) %", value=11.0)

    frt = st.number_input("FRT (cm)", value=20.0)
    ffd = st.number_input("FFD (cm)", value=-5.0)
    seat_step = st.number_input("åº§ä½ã‚¹ãƒ†ãƒƒãƒ— (å›/20ç§’)", value=30)

# --- è§£æç”¨é–¢æ•°ç¾¤ ---
mp_pose = mp.solutions.pose

def calculate_angle(a, b, c):
    a = np.array(a); b = np.array(b); c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0: angle = 360-angle
    return angle

def draw_grid(image, interval=50):
    """å§¿å‹¢è©•ä¾¡ç”¨ã®ã‚°ãƒªãƒƒãƒ‰ç·šã‚’æç”»"""
    h, w, _ = image.shape
    color = (200, 200, 200) 
    center_x = w // 2
    cv2.line(image, (center_x, 0), (center_x, h), (0, 255, 255), 1) 
    for x in range(0, w, interval):
        if x != center_x:
            cv2.line(image, (x, 0), (x, h), color, 1)
    for y in range(0, h, interval):
        cv2.line(image, (0, y), (w, y), color, 1)
    return image

def process_video(uploaded_file, view_type):
    if uploaded_file is None: return None, pd.DataFrame() # ç©ºDFã‚’è¿”ã™
    
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(uploaded_file.read())
    cap = cv2.VideoCapture(tfile.name)
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    data = []
    
    KEYPOINTS = [0, 11, 12, 23, 24, 25, 26, 27, 28, 31, 32]
    CONNECTIONS = [
        (11, 12), (23, 24), (11, 23), (12, 24), 
        (23, 25), (24, 26), (25, 27), (26, 28),
        (27, 31), (28, 32)
    ]

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        frame_idx = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            image = draw_grid(image, interval=width//10)

            # ã€ä¿®æ­£ç‚¹ã€‘åˆæœŸå€¤ã‚’NaNï¼ˆæ¬ æå€¤ï¼‰ã«ã—ã¦ãŠãã“ã¨ã§KeyErrorã‚’é˜²ã
            frame_data = {
                "frame": frame_idx,
                "l_knee": np.nan, "r_knee": np.nan,
                "shoulder_tilt": np.nan, "hip_tilt": np.nan,
                "sway": np.nan, "step_len": np.nan
            }
            
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                h_img, w_img, _ = image.shape
                
                def get_c(idx): return [landmarks[idx].x, landmarks[idx].y]
                def get_pix(idx): return int(landmarks[idx].x * w_img), int(landmarks[idx].y * h_img)
                
                # è¨ˆç®—å‡¦ç†
                l_knee = calculate_angle(get_c(23), get_c(25), get_c(27))
                r_knee = calculate_angle(get_c(24), get_c(26), get_c(28))
                shoulder_tilt = (landmarks[12].y - landmarks[11].y) * 100 
                hip_tilt = (landmarks[24].y - landmarks[23].y) * 100
                mid_sh_x = (landmarks[11].x + landmarks[12].x) / 2
                mid_hip_x = (landmarks[23].x + landmarks[24].x) / 2
                sway = (mid_hip_x - mid_sh_x) * 100
                step_len = abs(landmarks[27].x - landmarks[28].x) * 100
                
                # å€¤ã‚’ä¸Šæ›¸ã
                frame_data.update({
                    "l_knee": l_knee, "r_knee": r_knee,
                    "shoulder_tilt": shoulder_tilt, "hip_tilt": hip_tilt,
                    "sway": sway, "step_len": step_len
                })

                # æç”»
                for start, end in CONNECTIONS:
                    cv2.line(image, get_pix(start), get_pix(end), (255, 255, 255), 2)
                for idx in KEYPOINTS:
                    color = (0, 0, 255) if idx % 2 == 0 else (255, 0, 0)
                    cv2.circle(image, get_pix(idx), 6, color, -1)
            
            data.append(frame_data)
            out.write(image)
            frame_idx += 1
            
    cap.release()
    out.release()
    return output_path, pd.DataFrame(data)

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col1, col2 = st.columns(2)
with col1:
    st.subheader("â‘  æ­£é¢å‹•ç”» (Front)")
    file_front = st.file_uploader("æ­£é¢ã‹ã‚‰æ’®å½±", type=['mp4', 'mov'], key="f")
with col2:
    st.subheader("â‘¡ å´é¢å‹•ç”» (Side)")
    file_side = st.file_uploader("æ¨ªã‹ã‚‰æ’®å½±", type=['mp4', 'mov'], key="s")

if file_front and file_side and st.button("ğŸš€ è§£æé–‹å§‹"):
    with st.spinner("AIãŒå‹•ä½œã®å·¦å³å·®ã¨ãƒªã‚¹ã‚¯ã‚’è¨ˆç®—ä¸­..."):
        path_f, df_f = process_video(file_front, "front")
        path_s, df_s = process_video(file_side, "side")
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: è§£æå¤±æ•—ï¼ˆäººãŒæ˜ ã£ã¦ã„ãªã„ç­‰ï¼‰ã®å ´åˆ
        if df_f.empty or df_s.empty or df_f['sway'].isna().all():
            st.error("âš ï¸ è§£æã‚¨ãƒ©ãƒ¼: å‹•ç”»ã‹ã‚‰äººç‰©ã®éª¨æ ¼ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨èº«ãŒæ˜ ã£ã¦ã„ã‚‹å‹•ç”»ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.markdown("---")
            
            # 1. å‹•ç”»ã¨æ³¢å½¢
            c1, c2 = st.columns(2)
            with c1:
                st.video(path_f)
                st.caption("æ­£é¢ï¼šã‚°ãƒªãƒƒãƒ‰ã§å·¦å³ã®ãƒ–ãƒ¬ã‚’ç¢ºèª")
                fig, ax = plt.subplots(figsize=(5, 2))
                ax.plot(df_f['sway'], color='purple', label='éª¨ç›¤ã®æ¨ªæºã‚Œ')
                ax.axhline(0, color='gray', linestyle='--')
                ax.set_title("ä½“å¹¹ã«å¯¾ã™ã‚‹éª¨ç›¤ã®å·¦å³å‹•æº")
                ax.legend()
                st.pyplot(fig)
                
            with c2:
                st.video(path_s)
                st.caption("å´é¢ï¼šæ­©å¹…ã¨å§¿å‹¢ã‚’ç¢ºèª")
                fig2, ax2 = plt.subplots(figsize=(5, 2))
                ax2.plot(df_s['l_knee'], color='blue', label='å·¦è†', alpha=0.7)
                ax2.plot(df_s['r_knee'], color='red', label='å³è†', alpha=0.7)
                ax2.set_title("è†é–¢ç¯€ã®å±ˆæ›²è§’åº¦ (å·¦å³å·®ãƒã‚§ãƒƒã‚¯)")
                ax2.legend()
                st.pyplot(fig2)

            # 2. ãƒªã‚¹ã‚¯åˆ†æ
            st.header("ğŸ‘¨â€âš•ï¸ å‹•ä½œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
            alerts = []
            
            # A. è†ã®å·¦å³å·®
            max_l = df_s['l_knee'].max()
            max_r = df_s['r_knee'].max()
            diff_knee = abs(max_l - max_r)
            
            if diff_knee > 10:
                weak_side = "å·¦" if max_l < max_r else "å³"
                alerts.append(f"ğŸš¨ **è†ã®å‹•ãã«å¤§ããªå·¦å³å·®ã‚ã‚Š (å·®: {diff_knee:.1f}åº¦)**\n{weak_side}å´ã®è†ã®æ›²ãŒã‚ŠãŒæµ…ã„ã§ã™ã€‚ç—›ã¿ã‚’é¿ã‘ã¦ã„ã‚‹ã‹ã€å¯å‹•åŸŸåˆ¶é™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            
            # B. ã‚¹ã‚¦ã‚§ã‚¤
            sway_range = df_f['sway'].max() - df_f['sway'].min()
            if sway_range > 10: 
                reason = "ä¸­æ®¿ç­‹ã®ç­‹åŠ›ä½ä¸‹" if (one_leg_l < 20 or one_leg_r < 20) else "ä½“å¹¹æ©Ÿèƒ½ã®ä¸å®‰å®šã•"
                alerts.append(f"ğŸš¨ **æ­©è¡Œæ™‚ã®éª¨ç›¤å‹•æºï¼ˆãµã‚‰ã¤ãï¼‰ãŒå¤§ãã„**ã§ã™ã€‚\n{reason}ãŒç–‘ã‚ã‚Œã¾ã™ã€‚ï¼ˆç‰‡è„šç«‹ä½: L{one_leg_l}ç§’ / R{one_leg_r}ç§’ï¼‰")
            
            # C. æ¨é€²åŠ›
            step_avg = df_s['step_len'].mean()
            if step_avg < 15:
                alerts.append("âš ï¸ **æ­©å¹…ãŒå…¨ä½“çš„ã«å°ã•ã„**ã§ã™ã€‚\nè¶³è¶¾æŠŠæŒåŠ›ä½ä¸‹ã‚„ã€è‚¡é–¢ç¯€ã®ä¼¸å±•åˆ¶é™ï¼ˆè¹´ã‚Šå‡ºã—ä¸è¶³ï¼‰ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚")
            
            # D. æ©Ÿèƒ½ãƒ‡ãƒ¼ã‚¿ä¹–é›¢
            if toe_grip_l < 10 or toe_grip_r < 10:
                alerts.append("âš ï¸ **è¶³è¶¾æŠŠæŒåŠ›ãŒä½ä¸‹**ã—ã¦ã„ã¾ã™ï¼ˆåŸºæº–å€¤æœªæº€ï¼‰ã€‚\nã“ã‚ŒãŒã€Œè¹´ã‚Šå‡ºã—ä¸è¶³ã€ã‚„ã€Œãµã‚‰ã¤ãã€ã®æ ¹æœ¬åŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            if frt < 25:
                alerts.append("âš ï¸ **FRT(25cmæœªæº€)**ï¼šå‹•çš„ãƒãƒ©ãƒ³ã‚¹èƒ½åŠ›ãŒä½ä¸‹ã—ã¦ãŠã‚Šã€è»¢å€’ãƒªã‚¹ã‚¯ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚")

            if alerts:
                for a in alerts:
                    st.error(a)
            else:
                st.success("å‹•ä½œãƒãƒ©ãƒ³ã‚¹ã¯æ¯”è¼ƒçš„è‰¯å¥½ã§ã™ã€‚å¼•ãç¶šãå·¦å³å·®ã«æ³¨æ„ã—ã¦ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã—ã‚‡ã†ã€‚")

            st.info("â€» ã“ã®è§£æã¯ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ã™ã€‚ç¢ºå®šè¨ºæ–­ã¯å°‚é–€æ©Ÿé–¢ã§ã®è©•ä¾¡ãŒå¿…è¦ã§ã™ã€‚")
