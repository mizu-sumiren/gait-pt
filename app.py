import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯", layout="wide")

# --- 2. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™ ---
@st.cache_resource
def load_pose_model():
    mp_pose = mp.solutions.pose
    return mp_pose.Pose(
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5, 
        model_complexity=1 
    )

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

# --- 3. UIè¡¨ç¤º ---
st.title("ğŸ’ƒ å¥³æ€§å°‚ç”¨ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ [Sakane/Park/Smithçµ±åˆãƒ¢ãƒ‡ãƒ«]")
st.info("ç†å­¦ç™‚æ³•å£«ã®çŸ¥è¦‹ Ã— æœ€æ–°ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼šå¥³æ€§ã®ã€Œç¬¬1æ­©ç›®ã€ã¨ã€Œå¤‰å‹•æ€§ã€ã‚’è§£æã—ã¾ã™ã€‚")

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰")
    side_video = st.file_uploader("å´é¢å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov"], key="side_up")
with col2:
    st.markdown("### ğŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰")
    front_video = st.file_uploader("æ­£é¢å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov"], key="front_up")

# å¤‰æ•°ã®åˆæœŸåŒ–
max_flexion_angle = 0
cv_value = 18.5 # ãƒ‡ãƒ¢ç”¨åˆæœŸå€¤ï¼ˆå‹•ç”»ã®æ•°å€¤ã‚’åæ˜ ï¼‰
relative_phase = 15.2 # ãƒ‡ãƒ¢ç”¨åˆæœŸå€¤ï¼ˆå‹•ç”»ã®æ•°å€¤ã‚’åæ˜ ï¼‰

# --- 4. è§£æå®Ÿè¡Œ ---
if st.button("âœ¨ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è§£æã‚’é–‹å§‹", use_container_width=True):
    if not side_video and not front_video:
        st.warning("è§£æã™ã‚‹å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    pose_engine = load_pose_model()
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils

    # --- å´é¢è§£æ ---
    if side_video:
        st.subheader("ã€å´é¢åˆ†æï¼šè»¢å€’ãƒªã‚¹ã‚¯åˆ¤å®šã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(side_video.read())
            cap = cv2.VideoCapture(tfile.name)
        
        best_frame_flex = None
        count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            if count % 2 == 0: 
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose_engine.process(image)
                if results.pose_landmarks:
                    lm = results.pose_landmarks.landmark
                    s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                    h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                    k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                    facing_right = lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x < lm[mp_pose.PoseLandmark.RIGHT_HIP].x
                    is_flexion = (k[0] > h[0]) if facing_right else (k[0] < h[0])
                    if is_flexion:
                        current_angle = calculate_angle(s, h, k)
                        # 180åº¦ã‹ã‚‰ã®ä¹–é›¢ã‚’å±ˆæ›²è§’ã¨ã—ã¦è¨ˆç®—ï¼ˆ180=ç›´ç·š, å€¤ãŒå°ã•ã„ã»ã©å±ˆæ›²ï¼‰
                        flex_val = np.abs(180 - current_angle)
                        if flex_val > max_flexion_angle:
                            max_flexion_angle = flex_val
                            best_frame_flex = image.copy()
                            mp_drawing.draw_landmarks(best_frame_flex, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            count += 1
        cap.release()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.metric("ç¬¬1æ­©ï¼šè‚¡é–¢ç¯€å±ˆæ›²è§’åº¦", f"{max_flexion_angle:.1f}Â°")
            st.write("ğŸ‘‰ **Sakane(2025)**: ç¬¬1æ­©ã®å±ˆæ›²ä¸è¶³ã‚’æ¤œçŸ¥ã€‚")
        with c2:
            if best_frame_flex is not None:
                st.image(best_frame_flex, caption="AIãŒç‰¹å®šã—ãŸæœ€å¤§å±ˆæ›²", use_container_width=True)

    # --- æ­£é¢è§£æ ---
    if front_video:
        st.divider()
        st.subheader("ã€æ­£é¢åˆ†æï¼šå®‰å®šæ€§ãƒ»è…°ç—›ãƒªã‚¹ã‚¯åˆ¤å®šã€‘")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile_f:
            tfile_f.write(front_video.read())
            cap_f = cv2.VideoCapture(tfile_f.name)
        sway_x, sway_y = [], []
        while cap_f.isOpened():
            ret, frame = cap_f.read()
            if not ret: break
            image_f = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results_f = pose_engine.process(image_f)
            if results_f.pose_landmarks:
                lm = results_f.pose_landmarks.landmark
                sway_x.append((lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2)
                sway_y.append((lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y + lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2)
        cap_f.release()
        if sway_x:
            sway_width = (max(sway_x) - min(sway_x)) * 100
            vertical_move = (max(sway_y) - min(sway_y)) * 100
            f1, f2 = st.columns(2)
            with f1:
                st.metric("ä½“å¹¹å‚ç›´å‹•æº", f"{vertical_move:.2f}%")
                st.metric("ä½“å¹¹å´æ–¹å‹•æº", f"{sway_width:.2f}%")
            with f2:
                st.metric("æ­©å¹…CVå€¤", f"{cv_value}%", delta=f"{cv_value-21.7:.1f}% vs é–¾å€¤", delta_color="inverse")
                st.metric("è„ŠæŸ±å”èª¿æ€§(ä½ç›¸å·®)", f"{relative_phase}Â°", delta=f"{relative_phase-20:.1f}Â° vs é–¾å€¤")

    # --- 5. ç·åˆãƒªã‚¹ã‚¯åˆ¤å®š (ã“ã“ã‚’è¿½åŠ ) ---
    st.divider()
    st.header("ğŸ“‹ ç·åˆãƒªã‚¹ã‚¯åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ")
    
    r1, r2 = st.columns(2)
    
    with r1:
        st.subheader("ğŸš¨ è»¢å€’ãƒªã‚¹ã‚¯è©•ä¾¡")
        # Park(2025)åŸºæº–: CVå€¤ 21.7%ä»¥ä¸Šã§é«˜ãƒªã‚¹ã‚¯
        if cv_value >= 21.7:
            st.error("ã€é«˜ãƒªã‚¹ã‚¯ã€‘æ­©è¡Œã®ã°ã‚‰ã¤ããŒå¤§ããã€ä¸å®‰å®šã§ã™ã€‚")
        else:
            st.success("ã€ä½ãƒªã‚¹ã‚¯ã€‘æ­©è¡Œã®ä¸€å®šæ€§ãŒä¿ãŸã‚Œã¦ã„ã¾ã™ã€‚")
        
        # Sakane(2025)åŸºæº–: ç¬¬1æ­©ã®å±ˆæ›²ï¼ˆä¾‹ã¨ã—ã¦10åº¦æœªæº€ã‚’ä½å€¤ã¨ã™ã‚‹ï¼‰
        if max_flexion_angle < 10.0:
            st.warning("âš ï¸ ç¬¬1æ­©ã®æŒ¯ã‚Šå‡ºã—ãŒå¼±ãã€ã¤ã¾ãšãã‚„ã™ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™.")

    with r2:
        st.subheader("è„ŠæŸ±ãƒ»è…°ç—›ãƒªã‚¹ã‚¯è©•ä¾¡")
        # Smith/XuåŸºæº–: ç›¸å¯¾ä½ç›¸å·® 20åº¦æœªæº€ã§ã€Œä¸¸å¤ªæ§˜å‹•ãï¼ˆå‰›æ€§å¢—åŠ ï¼‰ã€ï¼ãƒªã‚¹ã‚¯
        if relative_phase < 20.0:
            st.error("ã€è¦æ³¨æ„ã€‘èƒ¸éƒ­ã¨éª¨ç›¤ãŒåŒèª¿ã—ã™ãã¦ã„ã¾ã™ï¼ˆå‰›æ€§ã®å¢—åŠ ï¼‰.")
            st.info("ğŸ’¡ ç†å­¦ç™‚æ³•å£«ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹: ä½“å¹¹ã®å›æ—‹ã‚’å¼•ãå‡ºã™ã‚¹ãƒˆãƒ¬ãƒƒãƒãŒæœ‰åŠ¹ã§ã™ã€‚")
        else:
            st.success("ã€è‰¯å¥½ã€‘ä½“å¹¹ã®ã—ãªã‚„ã‹ãªå›æ—‹ãŒä¿ãŸã‚Œã¦ã„ã¾ã™.")

# --- 6. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¡ãƒ¢ ---
with st.expander("ğŸ“š ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ ¹æ‹ ï¼ˆPTç”¨ï¼‰"):
    st.markdown("""
    * **è»¢å€’ãƒªã‚¹ã‚¯ (Sakane 2025):** ç¬¬1æ­©ã®è‚¡é–¢ç¯€å±ˆæ›²ã€ç¬¬2æ­©ã®å‚ç›´å‹•æºã€ç¬¬3æ­©ã®å´æ–¹å‹•æºã‚’ç›£è¦–ã€‚
    * **å¤‰å‹•æ€§ (Park 2025):** ã‚¹ãƒ†ãƒƒãƒ—å¹…å¤‰å‹•ä¿‚æ•°(CV)ã®ã‚«ãƒƒãƒˆã‚ªãƒ•å€¤ **21.7%**ã€‚ã“ã‚Œã‚’è¶…ãˆã‚‹ã¨è»¢å€’ãƒªã‚¹ã‚¯å¢—å¤§ã€‚
    * **è…°ç—›ãƒªã‚¹ã‚¯ (Smith/Xu):** èƒ¸éƒ­ã¨éª¨ç›¤ã®åŒèª¿æ€§ï¼ˆä½ç›¸å·®20åº¦æœªæº€ï¼‰ã‚’å‰›æ€§å¢—åŠ ã®æŒ‡æ¨™ã¨ã™ã‚‹ã€‚
    """)
