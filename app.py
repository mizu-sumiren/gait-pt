import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import io
import math
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from PIL import Image

# --- MediaPipeåˆæœŸåŒ– ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIå§¿å‹¢ãƒ»æ­©è¡Œåˆ†æãƒ©ãƒœ", page_icon="ğŸ¥", layout="wide")

# --- CSSè¨­å®š ---
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            .stDeployButton {display:none;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¢ãƒ¼ãƒ‰é¸æŠ ---
st.sidebar.header("âš™ï¸ åˆ†æãƒ¢ãƒ¼ãƒ‰")
app_mode = st.sidebar.radio(
    "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)", "å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Lite)", "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ (ç«‹ä½/åº§ä½)"]
)

# --- ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º ---
if "æ­©è¡Œ" in app_mode:
    st.title("ğŸƒâ€â™‚ï¸ AIæ­©è¡Œãƒ‰ãƒƒã‚¯")
    st.markdown(f"ãƒ¢ãƒ¼ãƒ‰: {app_mode}")
else:
    st.title("ğŸ“¸ AIå§¿å‹¢åˆ†æãƒ©ãƒœ")
    st.markdown("æ­£é¢(ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ) Ã— å´é¢(çŒ«èƒŒãƒ»FHP) ã®åŒæ™‚è©•ä¾¡")

# --- å¤‰æ•°åˆæœŸåŒ– ---
toe_grip_l = toe_grip_r = 0
hip_flex_l = hip_flex_r = 0
one_leg_l = one_leg_r = 0
frt = ffd = 0
pain_areas = []

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼å…¥åŠ› ---
st.sidebar.header("ğŸ“‹ å¯¾è±¡è€…æƒ…å ±")
client_name = st.sidebar.text_input("æ°å", "ãƒ†ã‚¹ãƒˆ å¤ªéƒ æ§˜")

# Proãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è©³ç´°å…¥åŠ›
if app_mode == "å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)":
    with st.sidebar.expander("1. å•è¨ºãƒ»ç—›ã¿", expanded=True):
        pain_areas = st.multiselect("ç—›ã¿", ["ãªã—", "é¦–", "è‚©", "è…°", "è‚¡é–¢ç¯€", "è†", "è¶³é¦–"])
    with st.sidebar.expander("2. èº«ä½“æ©Ÿèƒ½æ¸¬å®š", expanded=True):
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**å·¦ (L)**")
            grip_l = st.number_input("æ¡åŠ›L", 20.0); hip_flex_l = st.number_input("è‚¡å±ˆæ›²L", 0.9)
            one_leg_l = st.number_input("ç‰‡è„šL", 15.0); toe_grip_l = st.number_input("è¶³æŠŠæŒL", 10.0)
        with c2:
            st.markdown("**å³ (R)**")
            grip_r = st.number_input("æ¡åŠ›R", 25.0); hip_flex_r = st.number_input("è‚¡å±ˆæ›²R", 1.2)
            one_leg_r = st.number_input("ç‰‡è„šR", 60.0); toe_grip_r = st.number_input("è¶³æŠŠæŒR", 20.0)
        st.markdown("---")
        frt = st.number_input("FRT", 25.0); ffd = st.number_input("FFD", 0.0)

# --- å¹¾ä½•å­¦è¨ˆç®—é–¢æ•° ---
def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    rad = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(rad*180.0/np.pi)
    if angle > 180.0: angle = 360-angle
    return angle

def calculate_slope(a, b):
    if a is None or b is None: return 0
    return math.degrees(math.atan2(a[1]-b[1], a[0]-b[0]))

def calculate_vertical_angle(a, b):
    if a is None or b is None: return 0
    return math.degrees(math.atan2(b[0]-a[0], b[1]-a[1]))

# --- é™æ­¢ç”»åˆ†æãƒ­ã‚¸ãƒƒã‚¯ (ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆç‰ˆ) ---
def analyze_static_image(image, view, posture_type):
    with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:
        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if not results.pose_landmarks: return image, None

        h, w, _ = image.shape
        lms = results.pose_landmarks.landmark
        annotated_image = image.copy()
        
        # ã‚°ãƒªãƒƒãƒ‰ç·š
        cv2.line(annotated_image, (w//2, 0), (w//2, h), (0, 255, 255), 2)
        mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        def get_p(idx): return [lms[idx].x * w, lms[idx].y * h]
        metrics = {}

        # --- A. æ­£é¢å†™çœŸã®åˆ†æ ---
        if view == "front":
            # 1. é ­ã®å‚¾ã
            metrics['head_tilt'] = calculate_slope(get_p(7), get_p(8))
            # 2. è‚©ã®å‚¾ã
            metrics['shoulder_slope'] = calculate_slope(get_p(11), get_p(12))
            # 3. éª¨ç›¤ã®å‚¾ã (ç°¡æ˜“: 23-24)
            metrics['hip_slope'] = calculate_slope(get_p(23), get_p(24))

        # --- B. å´é¢å†™çœŸã®åˆ†æ ---
        elif view == "side":
            # 1. ã‚¹ãƒãƒ›é¦– (è€³7ã¨è‚©11ã®Xå·®)
            # ç”»é¢å³å‘ãã‹å·¦å‘ãã‹ã§ç¬¦å·ãŒå¤‰ã‚ã‚‹ãŸã‚çµ¶å¯¾å€¤ã§è·é›¢ã‚’è¦‹ã‚‹
            # ã“ã“ã§ã¯ã€Œè€³ãŒè‚©ã‚ˆã‚Šå‰ã«ã‚ã‚‹ã‹ã€ã‚’åˆ¤å®šã—ãŸã„
            ear_x = (lms[7].x + lms[8].x) / 2 # ä¸¡è€³ã®ä¸­ç‚¹ï¼ˆæ¨ªé¡”ãªã‚‰ç‰‡è€³ã ãŒå®‰å…¨ç­–ï¼‰
            shoulder_x = (lms[11].x + lms[12].x) / 2
            # ç”»åƒã®å¹…ã«å¯¾ã™ã‚‹å‰²åˆ(%)ã§ç®—å‡º
            metrics['forward_head_score'] = (ear_x - shoulder_x) * 100 
            
            # 2. ä½“å¹¹ã®å‰å‚¾
            metrics['trunk_lean'] = calculate_vertical_angle(get_p(11), get_p(23))
            
            # 3. è†ãƒ»è‚¡é–¢ç¯€ (å§¿å‹¢ã‚¿ã‚¤ãƒ—åˆ¥)
            if posture_type == "ç«‹ä½ (Standing)":
                metrics['knee_angle'] = calculate_angle(get_p(23), get_p(25), get_p(27))
            else: # åº§ä½
                metrics['hip_angle'] = calculate_angle(get_p(11), get_p(23), get_p(25))

        return annotated_image, metrics

# --- é™æ­¢ç”»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ ---
def generate_static_feedback(f_metrics, s_metrics, posture_type):
    fb = []
    
    # æ­£é¢
    if f_metrics:
        if abs(f_metrics['head_tilt']) > 3.0: fb.append("âš ï¸ **ã€é ­éƒ¨ã®å‚¾ãã€‘** æ­£é¢ã‹ã‚‰è¦‹ã¦é¦–ãŒå‚¾ã„ã¦ã„ã¾ã™ã€‚")
        slope = f_metrics['shoulder_slope']
        if abs(slope) > 3.0: 
            side = "å³" if slope > 0 else "å·¦"
            fb.append(f"âš ï¸ **ã€è‚©ã®é«˜ã•ã€‘** {side}è‚©ãŒä¸‹ãŒã£ã¦ã„ã¾ã™ã€‚")
    
    # å´é¢
    if s_metrics:
        # FHPåˆ¤å®šï¼ˆå‘ãã«ã‚ˆã‚‹ãŒã€æ•°å€¤ãŒå¤§ãã„ï¼ã‚ºãƒ¬ãŒå¤§ãã„ã¨åˆ¤æ–­ï¼‰
        if abs(s_metrics['forward_head_score']) > 5.0: 
            fb.append("âš ï¸ **ã€ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãƒãƒƒã‚¯å‚¾å‘ã€‘** é ­ãŒè‚©ã‚ˆã‚Šå‰ã«å‡ºã¦ã„ã¾ã™ï¼ˆã‚¹ãƒãƒ›é¦–ï¼‰ã€‚")
        
        if abs(s_metrics['trunk_lean']) > 10: 
            fb.append("âš ï¸ **ã€çŒ«èƒŒãƒ»åã‚Šè…°ã€‘** ä¸ŠåŠèº«ã®è»¸ãŒå‚ç›´ã‹ã‚‰å‚¾ã„ã¦ã„ã¾ã™ã€‚")

        if posture_type == "ç«‹ä½ (Standing)":
            if s_metrics.get('knee_angle', 180) < 165: fb.append("â„¹ï¸ **ã€è†æ›²ãŒã‚Šã€‘** è†ãŒä¼¸ã³åˆ‡ã£ã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            if s_metrics.get('hip_angle', 90) > 110: fb.append("â„¹ï¸ **ã€ä»™éª¨åº§ã‚Šã€‘** éª¨ç›¤ãŒå¾Œã‚ã«å€’ã‚Œã€è…°ã¸ã®è² æ‹…ãŒå¤§ãã„åº§ã‚Šæ–¹ã§ã™ã€‚")

    if not fb: fb.append("âœ… **ã‚°ãƒƒãƒ‰ãƒã‚¹ãƒãƒ£ãƒ¼ï¼** éå¸¸ã«ç¶ºéº—ãªå§¿å‹¢ã§ã™ã€‚")
    return fb

# --- å‹•ç”»åˆ†æé–¢æ•° (æ—¢å­˜) ---
def analyze_video_metrics(history, fps):
    if not history: return None
    dists = []
    for lms in history:
        la, ra = np.array([lms[27].x, lms[27].y]), np.array([lms[28].x, lms[28].y])
        dists.append(np.linalg.norm(la - ra))
    steps = 0; thresh = np.mean(dists)
    for i in range(1, len(dists)-1):
        if dists[i] > dists[i-1] and dists[i] > dists[i+1] and dists[i] > thresh: steps += 1
    duration = len(history) / fps
    cadence = (steps / duration) * 60 if duration > 0 else 0
    return {"cadence": cadence, "steps": steps}

def process_video(file):
    if not file: return None, None
    tfile = tempfile.NamedTemporaryFile(delete=False); tfile.write(file.read())
    cap = cv2.VideoCapture(tfile.name)
    w, h, fps = int(cap.get(3)), int(cap.get(4)), int(cap.get(5))
    path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
    history = []
    with mp_pose.Pose() as pose:
        while cap.isOpened():
            ret, img = cap.read()
            if not ret: break
            img.flags.writeable = False; res = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            img.flags.writeable = True; img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            cv2.line(img, (w//2,0), (w//2,h), (0,255,255), 1)
            if res.pose_landmarks:
                mp_drawing.draw_landmarks(img, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                history.append(res.pose_landmarks.landmark)
            out.write(img)
    cap.release(); out.release()
    return path, analyze_video_metrics(history, fps)

# --- PDFç”Ÿæˆ ---
def create_pdf(title, name, feedbacks, vid=None, f_stat=None, s_stat=None):
    b = io.BytesIO()
    c = canvas.Canvas(b, pagesize=A4); h = A4[1]
    c.setFont("Helvetica-Bold", 16); c.drawString(50, h-50, f"Report: {title}")
    c.setFont("Helvetica", 12); c.drawString(50, h-80, f"Name: {name}")
    
    y = h-120
    c.setFont("Helvetica-Bold", 12); c.drawString(50, y, "Metrics Data")
    y -= 20; c.setFont("Helvetica", 10)
    
    if vid:
        c.drawString(60, y, f"Cadence: {vid['cadence']:.1f} steps/min / Steps: {vid['steps']}")
    
    if f_stat:
        y -= 20; c.drawString(60, y, "[Front View]")
        c.drawString(70, y-15, f"Head Tilt: {f_stat['head_tilt']:.1f} deg")
        c.drawString(200, y-15, f"Shoulder Slope: {f_stat['shoulder_slope']:.1f} deg")
        y -= 30
        
    if s_stat:
        c.drawString(60, y, "[Side View]")
        c.drawString(70, y-15, f"FHP Score: {s_stat['forward_head_score']:.1f}")
        c.drawString(200, y-15, f"Trunk Lean: {s_stat['trunk_lean']:.1f} deg")

    y -= 40; c.setFont("Helvetica-Bold", 12); c.drawString(50, y, "AI Feedback")
    y -= 20; c.setFont("Helvetica", 10)
    c.drawString(60, y, "See app screen for detailed analysis.")
    
    c.showPage(); c.save(); b.seek(0)
    return b

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# A. é™æ­¢ç”»åˆ†æãƒ¢ãƒ¼ãƒ‰ (ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼)
if app_mode == "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ (ç«‹ä½/åº§ä½)":
    st.info("ğŸ“¸ æ­£é¢ãƒ»å´é¢ãã‚Œãã‚Œã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆç‰‡æ–¹ã®ã¿ã‚‚å¯ï¼‰")
    posture_type = st.radio("å§¿å‹¢ã‚¿ã‚¤ãƒ—", ["ç«‹ä½ (Standing)", "åº§ä½ (Sitting)"], horizontal=True)
    
    # 2ã‚«ãƒ©ãƒ ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’è¡¨ç¤º
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("â‘  æ­£é¢å†™çœŸ")
        file_f = st.file_uploader("Front Image", type=['jpg','png','jpeg'], key="sf")
    with c2:
        st.subheader("â‘¡ å´é¢å†™çœŸ")
        file_s = st.file_uploader("Side Image", type=['jpg','png','jpeg'], key="ss")
    
    if st.button("ğŸš€ å§¿å‹¢åˆ†æã‚’å®Ÿè¡Œ"):
        f_img, f_met, s_img, s_met = None, None, None, None
        
        # 1. æ­£é¢åˆ†æ
        if file_f:
            img = np.array(Image.open(file_f))
            f_img, f_met = analyze_static_image(img, "front", posture_type)
        
        # 2. å´é¢åˆ†æ
        if file_s:
            img = np.array(Image.open(file_s))
            s_img, s_met = analyze_static_image(img, "side", posture_type)
            
        if f_met or s_met:
            # ç”»åƒè¡¨ç¤º
            col1, col2 = st.columns(2)
            with col1:
                if f_img is not None: st.image(f_img, caption="æ­£é¢è§£æ", use_container_width=True)
            with col2:
                if s_img is not None: st.image(s_img, caption="å´é¢è§£æ", use_container_width=True)

            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.subheader("ğŸ“Š ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè¨ˆæ¸¬å€¤")
            d1, d2 = st.columns(2)
            with d1:
                st.markdown("##### æ­£é¢ãƒ‡ãƒ¼ã‚¿")
                if f_met:
                    st.metric("é ­éƒ¨ã®å‚¾ã", f"{f_met['head_tilt']:.1f}Â°")
                    st.metric("è‚©ã®å‚¾ã", f"{f_met['shoulder_slope']:.1f}Â°")
                else: st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")
            with d2:
                st.markdown("##### å´é¢ãƒ‡ãƒ¼ã‚¿")
                if s_met:
                    st.metric("ä½“å¹¹å‰å‚¾", f"{s_met['trunk_lean']:.1f}Â°")
                    val = s_met.get('knee_angle') if posture_type == "ç«‹ä½ (Standing)" else s_met.get('hip_angle')
                    label = "è†ä¼¸å±•" if posture_type == "ç«‹ä½ (Standing)" else "è‚¡é–¢ç¯€å±ˆæ›²"
                    st.metric(label, f"{val:.1f}Â°")
                else: st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            st.header("ğŸ‘¨â€âš•ï¸ AIå§¿å‹¢ãƒ¬ãƒãƒ¼ãƒˆ")
            feedbacks = generate_static_feedback(f_met, s_met, posture_type)
            for msg in feedbacks:
                if "âš ï¸" in msg: st.error(msg)
                elif "â„¹ï¸" in msg: st.warning(msg)
                else: st.success(msg)

            # ä¿å­˜
            pdf = create_pdf("Posture Analysis", client_name, feedbacks, f_stat=f_met, s_stat=s_met)
            st.download_button("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜", pdf, "posture_report.pdf", "application/pdf")
            
        else:
            st.warning("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

# B. å‹•ç”»åˆ†æãƒ¢ãƒ¼ãƒ‰ (æ—¢å­˜æ©Ÿèƒ½)
else:
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("â‘  æ­£é¢å‹•ç”»")
        file_f = st.file_uploader("Front Video", type=['mp4', 'mov'], key="vf")
    with c2:
        st.subheader("â‘¡ å´é¢å‹•ç”»")
        file_s = st.file_uploader("Side Video", type=['mp4', 'mov'], key="vs")

    if st.button("ğŸš€ æ­©è¡Œåˆ†æã‚’å®Ÿè¡Œ"):
        path_f, met_f = process_video(file_f)
        path_s, met_s = process_video(file_s)
        
        main_met = met_s if met_s else met_f
        
        st.markdown("---")
        c1, c2 = st.columns(2)
        with c1: 
            if path_f: st.video(path_f)
        with c2: 
            if path_s: st.video(path_s)

        if main_met:
            st.subheader("ğŸ“Š æ­©è¡Œãƒ‡ãƒ¼ã‚¿")
            st.metric("ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹", f"{main_met['cadence']:.1f} æ­©/åˆ†")
            st.success(f"æ¤œå‡ºæ­©æ•°: {main_met['steps']}æ­©")
            
            fb = ["âœ… è§£æå®Œäº†ã€‚è©³ç´°ã¯PDFã‚’ã”ç¢ºèªãã ã•ã„ã€‚"]
            if main_met['cadence'] < 100: fb.append("â„¹ï¸ ãƒšãƒ¼ã‚¹ãŒã‚†ã£ãã‚Šã§ã™ã€‚")
            
            for msg in fb: st.info(msg)
            
            pdf = create_pdf("Gait Analysis", client_name, fb, vid=main_met)
            st.download_button("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜", pdf, "gait_report.pdf", "application/pdf")
