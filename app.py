import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import io
import math
from datetime import datetime
from PIL import Image

from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.lib.utils import ImageReader

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²
try:
    pdfmetrics.registerFont(UnicodeCIDFont("HeiseiKakuGo-W5"))
    JP_FONT = "HeiseiKakuGo-W5"
except:
    JP_FONT = "Helvetica"

# MediaPipeã®æ¨™æº–çš„ãªåˆæœŸåŒ–
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

st.set_page_config(page_title="AIå§¿å‹¢ãƒ»æ­©è¡Œåˆ†æãƒ©ãƒœ", page_icon="ğŸ¥", layout="wide")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("âš™ï¸ åˆ†æãƒ¢ãƒ¼ãƒ‰")
app_mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰", ["å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)", "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ"])

st.sidebar.header("ğŸ“‹ å¯¾è±¡è€…æƒ…å ±")
client_name = st.sidebar.text_input("æ°å", "ãƒ†ã‚¹ãƒˆ æ§˜")
client_gender = st.sidebar.selectbox("æ€§åˆ¥", ["å¥³æ€§", "ç”·æ€§"])
client_height_cm = st.sidebar.number_input("èº«é•· (cm)", value=160)

is_female_mode = (client_gender == "å¥³æ€§" and "æ­©è¡Œ" in app_mode)

if is_female_mode:
    st.title("ğŸƒâ€â™‚ï¸ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ (å¥³æ€§å°‚ç”¨ãƒ»è©³ç´°ç‰ˆ)")
else:
    st.title("ğŸƒâ€â™‚ï¸ AIæ­©è¡Œãƒ‰ãƒƒã‚¯")

# --- å¥³æ€§å°‚ç”¨ï¼š5æŒ‡æ¨™è§£æãƒ­ã‚¸ãƒƒã‚¯ ---
def analyze_female_specific_gait(lms_history, fps, w, h, height_cm):
    if not lms_history or len(lms_history) < 10: return None
    left_y = [l[27].y if l else 1.0 for l in lms_history]
    right_y = [l[28].y if l else 1.0 for l in lms_history]
    
    def get_peaks(arr):
        p = []
        th = np.percentile(arr, 60)
        for i in range(1, len(arr)-1):
            if arr[i] > arr[i-1] and arr[i] > arr[i+1] and arr[i] > th: p.append(i)
        return p

    l_p, r_p = get_peaks(left_y), get_peaks(right_y)
    all_p = sorted([(p, 'L') for p in l_p] + [(p, 'R') for p in r_p])
    scores = {}

    if len(all_p) >= 3:
        step1, step2, step3 = range(0, all_p[0][0]), range(all_p[0][0], all_p[1][0]), range(all_p[1][0], all_p[2][0])
        # 1. è‚¡é–¢ç¯€å¯å‹•åŸŸ (30)
        h_angs = [calculate_angle([l[11].x*w, l[11].y*h], [l[23].x*w, l[23].y*h], [l[25].x*w, l[25].y*h]) for i in step1 if (l:=lms_history[i])]
        scores['è‚¡é–¢ç¯€ã®ä¼¸ã³'] = min(30, ( (max(h_angs)-min(h_angs)) / 35) * 30) if h_angs else 0
        # 2. ä½“å¹¹æºã‚Œ (30)
        sways = [(l[23].x + l[24].x)/2 for i in step3 if (l:=lms_history[i])]
        scores['ä½“å¹¹ã®å®‰å®šæ€§'] = max(0, 30 - (np.std(sways)*150)) if sways else 0
        # 3. å‚ç›´ç§»å‹• (15)
        verts = [(l[23].y + l[24].y)/2 for i in step2 if (l:=lms_history[i])]
        scores['è¡æ’ƒå¸å'] = min(15, (((max(verts)-min(verts))*height_cm) / 5) * 15) if verts else 0
        # 4. è†å¯å‹•åŸŸ (15)
        k_angs = [calculate_angle([l[23].x*w, l[23].y*h], [l[25].x*w, l[25].y*h], [l[27].x*w, l[27].y*h]) for i in list(step2)+list(step3) if (l:=lms_history[i])]
        scores['è†ã®ã‚¯ãƒƒã‚·ãƒ§ãƒ³'] = min(15, ((max(k_angs)-min(k_angs)) / 60) * 15) if k_angs else 0
        # 5. éŠè„šç›¸ç‡ (10)
        scores['è¶³ã®æŒ¯ã‚Šå‡ºã—'] = min(10, ((len(step1)/(all_p[1][0] if len(all_p)>1 else 1)*100) / 40) * 10)

    return {"total": sum(scores.values()), "scores": scores}

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    rad = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(rad * 180.0 / np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle

# --- è§£æå®Ÿè¡Œ ---
if "æ­©è¡Œ" in app_mode:
    video_file = st.file_uploader("ğŸ¥ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov"])
    if st.button("ğŸš€ è§£æé–‹å§‹") and video_file:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(video_file.read())
        cap = cv2.VideoCapture(tfile.name)
        w, h, fps = int(cap.get(3)), int(cap.get(4)), int(cap.get(5))
        lms_history, out_path = [], tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
        
        with mp_pose.Pose(min_detection_confidence=0.5) as pose:
            while cap.isOpened():
                ret, img = cap.read()
                if not ret: break
                res = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                if res.pose_landmarks:
                    mp_drawing.draw_landmarks(img, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                    lms_history.append(res.pose_landmarks.landmark)
                else: lms_history.append(None)
                out.write(img)
        cap.release(); out.release()
        
        st.video(out_path)
        if is_female_mode:
            res = analyze_female_specific_gait(lms_history, fps, w, h, client_height_cm)
            if res:
                st.header(f"ç·åˆã‚¹ã‚³ã‚¢: {res['total']:.1f} ç‚¹")
                cols = st.columns(5)
                for col, (lab, val) in zip(cols, res['scores'].items()):
                    col.metric(lab, f"{val:.1f}")
