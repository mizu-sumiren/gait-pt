import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import io
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import os

# --- MediaPipeåˆæœŸåŒ– ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
# initial_sidebar_state="expanded" ã‚’è¿½åŠ ã—ã¦ã€PCã§ã¯æœ€åˆã‹ã‚‰é–‹ãã‚ˆã†ã«è¨­å®š
st.set_page_config(page_title="AIæ­©è¡Œè§£æã‚¢ãƒ—ãƒª", page_icon="ğŸ›¡ï¸", layout="wide", initial_sidebar_state="expanded")

# --- ç”»é¢è¨­å®šï¼šä¿®æ­£ç®‡æ‰€ ---
# header {visibility: hidden;} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ã“ã‚Œã§å·¦ä¸Šã®ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            .stDeployButton {display:none;}
            /* header {visibility: hidden;} â†ã“ã“ã‚’å‰Šé™¤ã—ã¾ã—ãŸ */
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.title("ğŸƒâ€â™‚ï¸ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ - Smart Gait Lab")
st.markdown("èº«ä½“æ©Ÿèƒ½è©•ä¾¡ Ã— AIæ­©è¡Œåˆ†æ Ã— è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè©³ç´°ãªæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯ ---
st.sidebar.header("ğŸ“‹ æ¸¬å®šãƒ‡ãƒ¼ã‚¿å…¥åŠ›")

with st.sidebar.expander("1. åŸºæœ¬æƒ…å ±ãƒ»å•è¨º", expanded=True):
    client_name = st.text_input("æ°å", "ãƒ†ã‚¹ãƒˆ å¤ªéƒ æ§˜")
    pain_areas = st.multiselect(
        "ç—›ã¿ãƒ»é•å’Œæ„Ÿã®ã‚ã‚‹éƒ¨ä½",
        ["ç‰¹ã«ãªã—", "é¦–", "è‚©", "è…°", "è‚¡é–¢ç¯€(å³)", "è‚¡é–¢ç¯€(å·¦)", "è†(å³)", "è†(å·¦)", "è¶³é¦–ãƒ»è¶³éƒ¨"]
    )

with st.sidebar.expander("2. èº«ä½“æ©Ÿèƒ½æ¸¬å®šçµæœ", expanded=True):
    st.caption("å¯¾è±¡è€…ã®æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    col_s1, col_s2 = st.columns(2)
    with col_s1:
        st.markdown("**å·¦å´ (Left)**")
        grip_l = st.number_input("æ¡åŠ›(å·¦) kg", value=20.0)
        hip_flex_l = st.number_input("è‚¡å±ˆæ›²(å·¦) kgf/kg", value=0.9)
        one_leg_l = st.number_input("ç‰‡è„šç«‹ä½(å·¦) ç§’", value=15.0)
        toe_grip_l = st.number_input("è¶³è¶¾æŠŠæŒ(å·¦) %", value=10.0)
    with col_s2:
        st.markdown("**å³å´ (Right)**")
        grip_r = st.number_input("æ¡åŠ›(å³) kg", value=25.0)
        hip_flex_r = st.number_input("è‚¡å±ˆæ›²(å³) kgf/kg", value=1.2)
        one_leg_r = st.number_input("ç‰‡è„šç«‹ä½(å³) ç§’", value=60.0)
        toe_grip_r = st.number_input("è¶³è¶¾æŠŠæŒ(å³) %", value=20.0)

    st.markdown("---")
    frt = st.number_input("FRT (cm)", value=25.0)
    ffd = st.number_input("FFD (cm)", value=0.0)
    seat_step = st.number_input("åº§ä½ã‚¹ãƒ†ãƒƒãƒ— (å›/20ç§’)", value=30)

# --- é–¢æ•°ï¼šæ­©è¡ŒæŒ‡æ¨™ï¼ˆã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ãƒ»æ­©å¹…ï¼‰ã®è¨ˆç®— ---
def analyze_gait_metrics(landmarks_history, fps):
    if not landmarks_history:
        return None

    ankle_distances = []
    shin_lengths = []

    for lms in landmarks_history:
        la = np.array([lms[27].x, lms[27].y])
        ra = np.array([lms[28].x, lms[28].y])
        lk = np.array([lms[25].x, lms[25].y])
        
        dist = np.linalg.norm(la - ra)
        ankle_distances.append(dist)
        
        shin_len = np.linalg.norm(lk - la)
        shin_lengths.append(shin_len)

    steps = 0
    peaks = []
    threshold = np.mean(ankle_distances)
    
    for i in range(1, len(ankle_distances)-1):
        prev = ankle_distances[i-1]
        curr = ankle_distances[i]
        nex = ankle_distances[i+1]
        if curr > prev and curr > nex and curr > threshold:
            steps += 1
            peaks.append(curr)

    duration_sec = len(landmarks_history) / fps
    cadence = (steps / duration_sec) * 60 if duration_sec > 0 else 0
    
    avg_step_pixel = np.mean(peaks) if peaks else 0
    avg_shin_pixel = np.mean(shin_lengths) if shin_lengths else 1
    normalized_step_length = avg_step_pixel / avg_shin_pixel

    return {
        "steps": steps,
        "duration": duration_sec,
        "cadence": cadence,
        "step_ratio": normalized_step_length
    }

# --- é–¢æ•°ï¼šPDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ---
def create_pdf(client_name, data, feedbacks, gait_metrics):
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4

    try:
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒã‚ã‚Œã°è¨­å®šï¼ˆãªã‘ã‚Œã°è‹±èªã§ä»£ç”¨ï¼‰
        c.setFont("Helvetica-Bold", 16)
        c.drawString(50, height - 50, f"Gait & Physical Analysis Report")
        c.setFont("Helvetica", 10)
        c.drawString(50, height - 70, "Note: Japanese font required for full text support.")
    except:
        c.setFont("Helvetica-Bold", 16)
        c.drawString(50, height - 50, "Analysis Report")

    y = height - 100
    c.setFont("Helvetica", 12)
    c.drawString(50, y, f"Name: {client_name}")
    y -= 20
    c.drawString(50, y, f"Date: 2025/12/03")
    
    y -= 40
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, y, "1. Gait Analysis (AI Video)")
    y -= 20
    c.setFont("Helvetica", 11)
    if gait_metrics:
        c.drawString(60, y, f"Cadence: {gait_metrics['cadence']:.1f} steps/min")
        c.drawString(250, y, f"Step Ratio: {gait_metrics['step_ratio']:.2f} (Step/Leg Length)")
    else:
        c.drawString(60, y, "No video data analyzed.")

    y -= 40
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, y, "2. Physical Functions")
    y -= 20
    c.setFont("Helvetica", 11)
    c.drawString(60, y, f"Toe Grip: L {data['toe_l']}% / R {data['toe_r']}%")
    c.drawString(250, y, f"One Leg Stand: L {data['ols_l']}s / R {data['ols_r']}s")
    y -= 20
    c.drawString(60, y, f"Hip Flexion: L {data['hip_l']} / R {data['hip_r']}")
    c.drawString(250, y, f"FRT: {data['frt']}cm  /  FFD: {data['ffd']}cm")

    y -= 40
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, y, "3. AI PT Feedback")
    c.setFont("Helvetica", 10)
    y -= 20
    c.drawString(60, y, "Please refer to the app screen for detailed feedback.")

    c.showPage()
    c.save()
    buffer.seek(0)
    return buffer

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ï¼šè‡¨åºŠæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆèº«ä½“æ©Ÿèƒ½Ã—æ­©è¡Œã®çµ±åˆï¼‰ ---
def generate_clinical_feedback(data):
    feedback = []
    
    # ãƒ‡ãƒ¼ã‚¿å±•é–‹
    pain = data['pain']
    toe_l, toe_r = data['toe_l'], data['toe_r']
    hip_l, hip_r = data['hip_l'], data['hip_r']
    ols_l, ols_r = data['ols_l'], data['ols_r']
    frt, ffd = data['frt'], data['ffd']
    
    # 1. è¶³è¶¾æ©Ÿèƒ½ã¨æ­©è¡Œã®è¹´ã‚Šå‡ºã—
    avg_toe = (toe_l + toe_r) / 2
    if avg_toe < 15:
        feedback.append(f"**ã€è¶³æŒ‡æ©Ÿèƒ½ä½ä¸‹ Ã— æ­©è¡Œæ¨é€²åŠ›ã€‘**\nè¶³æŒ‡ã®åŠ›ãŒå¼±ã„ãŸã‚ï¼ˆå¹³å‡{avg_toe:.1f}%ï¼‰ã€æ­©è¡Œæ™‚ã«åœ°é¢ã‚’è¹´ã‚‹åŠ›ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã“ã‚ŒãŒ**ã€Œãƒšã‚¿ãƒšã‚¿æ­©ãã€ã‚„ã€Œæ­©å¹…ã®æ¸›å°‘ã€**ã«ç›´çµã—ã¦ã„ã¾ã™ã€‚")
    
    # 2. è‚¡é–¢ç¯€æ©Ÿèƒ½ã¨ã¤ã¾ãšããƒªã‚¹ã‚¯
    if hip_l < 1.0 or hip_r < 1.0:
        weak_side = "å·¦" if hip_l < hip_r else "å³"
        feedback.append(f"**ã€è‚¡é–¢ç¯€ç­‹åŠ›ä½ä¸‹ Ã— ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ã€‘**\n{weak_side}å´ã®è…¸è…°ç­‹å‡ºåŠ›ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚è¶³ã‚’æŒ¯ã‚Šå‡ºã™éš›ã«é«˜ã•ãŒä¸è¶³ã—ã€**ã€Œã™ã‚Šè¶³ã€ã‚„ã€Œå°ã•ãªæ®µå·®ã§ã®ã¤ã¾ãšãã€**ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚")
    
    # 3. å·¦å³å·®ã¨ä»£å„Ÿå‹•ä½œ
    diff_hip = abs(hip_l - hip_r)
    if diff_hip > 0.2:
        weaker = "å·¦" if hip_l < hip_r else "å³"
        stronger = "å³" if hip_l < hip_r else "å·¦"
        feedback.append(f"**ã€æ©Ÿèƒ½å·¦å³å·® Ã— æ­©è¡Œãƒªã‚ºãƒ ã€‘**\nç­‹åŠ›ãƒãƒ©ãƒ³ã‚¹ã®å´©ã‚Œã«ã‚ˆã‚Šã€æ­©è¡Œã®ãƒªã‚ºãƒ ãŒä¸å‡ç­‰ã«ãªã£ã¦ã„ã¾ã™ã€‚**å¼±ã„{weaker}å´ã‚’æ—©ãæ¥åœ°ã•ã›ã‚ˆã†ã¨ã™ã‚‹ãŸã‚ã€åå¯¾å´ã®{stronger}å´ã«éåº¦ãªè² æ‹…**ãŒã‹ã‹ã£ã¦ã„ã¾ã™ã€‚")

    # 4. ãƒãƒ©ãƒ³ã‚¹æ©Ÿèƒ½ã¨ã‚¹ã‚¦ã‚§ã‚¤
    if ols_l < 20 or ols_r < 20:
        unstable = "å·¦" if ols_l < 20 else "å³"
        feedback.append(f"**ã€ç«‹ä½ãƒãƒ©ãƒ³ã‚¹ä½ä¸‹ Ã— é‡å¿ƒå‹•æºã€‘**\nç‰‡è„šç«‹ä½ãŒä¸å®‰å®šï¼ˆ{unstable}å´ï¼‰ã§ã™ã€‚æ­©è¡Œã®ç«‹è„šæœŸã«éª¨ç›¤ã‚’å®‰å®šã•ã›ã‚‹ã“ã¨ãŒã§ããšã€**ã€Œå¤–å´ã¸ã®ãµã‚‰ã¤ãï¼ˆãƒ©ãƒ†ãƒ©ãƒ«ã‚¹ã‚¦ã‚§ã‚¤ï¼‰ã€**ãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚")

    # 5. é‡å¿ƒç§»å‹•èƒ½åŠ›
    if frt < 30:
        feedback.append(f"**ã€å‰æ–¹é‡å¿ƒç§»å‹•åˆ¶é™ Ã— å¾Œæ–¹é‡å¿ƒã€‘**\nFRTãŒ{frt}cmã¨çŸ­ç¸®ã—ã¦ã„ã¾ã™ã€‚è»¢å€’ã¸ã®ææ€–å¿ƒã‹ã‚‰**ã€Œè…°ãŒå¼•ã‘ãŸå§¿å‹¢ã€**ã«ãªã‚Šã‚„ã™ãã€ã‚¹ãƒ ãƒ¼ã‚ºãªä½“é‡ç§»å‹•ãŒé˜»å®³ã•ã‚Œã¦ã„ã¾ã™ã€‚")

    if not feedback:
        feedback.append("âœ… **ç´ æ™´ã‚‰ã—ã„çŠ¶æ…‹ã§ã™ï¼**\nèº«ä½“æ©Ÿèƒ½ã¨æ­©è¡Œå§¿å‹¢ã®çµ±åˆåˆ†æã®çµæœã€ç›®ç«‹ã£ãŸå´©ã‚Œã¯è¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã®æ©Ÿèƒ½ã‚’ç¶­æŒã—ã¾ã—ã‚‡ã†ã€‚")

    return feedback

# --- å‹•ç”»å‡¦ç†é–¢æ•° ---
def draw_grid_and_skeleton(image, results):
    h, w, _ = image.shape
    color_grid = (200, 200, 200)
    center_x = w // 2
    cv2.line(image, (center_x, 0), (center_x, h), (0, 255, 255), 1) 
    for x in range(0, w, w//8):
        if x != center_x: cv2.line(image, (x, 0), (x, h), color_grid, 1)
    
    if results.pose_landmarks:
        mp_drawing.draw_landmarks(
            image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
            mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2),
            mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2)
        )
    return image

def process_video_and_analyze(uploaded_file):
    if uploaded_file is None: return None, None
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(uploaded_file.read())
    cap = cv2.VideoCapture(tfile.name)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    landmarks_history = []

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            image = draw_grid_and_skeleton(image, results)
            out.write(image)
            
            if results.pose_landmarks:
                landmarks_history.append(results.pose_landmarks.landmark)

    cap.release()
    out.release()
    
    metrics = analyze_gait_metrics(landmarks_history, fps)
    return output_path, metrics

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col1, col2 = st.columns(2)
with col1:
    st.subheader("â‘  æ­£é¢å‹•ç”»")
    file_front = st.file_uploader("Front View", type=['mp4', 'mov'], key="f")
with col2:
    st.subheader("â‘¡ å´é¢å‹•ç”» (åˆ†ææ¨å¥¨)")
    file_side = st.file_uploader("Side View", type=['mp4', 'mov'], key="s")

if st.button("ğŸš€ æ±ç”¨åˆ†æã‚’å®Ÿè¡Œ"):
    path_f, metrics_f = process_video_and_analyze(file_front)
    path_s, metrics_s = process_video_and_analyze(file_side)
    
    main_metrics = metrics_s if metrics_s else metrics_f
    
    st.markdown("---")
    
    # 1. çµæœè¡¨ç¤ºã‚«ãƒ©ãƒ 
    res_c1, res_c2 = st.columns([2, 1])
    
    with res_c1:
        st.subheader("ğŸ¥ è§£æå‹•ç”»")
        v_col1, v_col2 = st.columns(2)
        with v_col1:
            if path_f: st.video(path_f)
        with v_col2:
            if path_s: st.video(path_s)
            
    with res_c2:
        st.subheader("ğŸ“Š æ­©è¡ŒAIãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        if main_metrics:
            st.metric("ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ (æ­©æ•°/åˆ†)", f"{main_metrics['cadence']:.1f}", delta="æ¨™æº–: 110-120")
            st.metric("æ­©å¹…æ¯”ç‡ (æ­©å¹…/ä¸‹è…¿é•·)", f"{main_metrics['step_ratio']:.2f}", help="1.0ä»¥ä¸ŠãŒç†æƒ³çš„")
            st.info(f"æ¤œå‡º: {main_metrics['steps']}æ­© / {main_metrics['duration']:.1f}ç§’")
        else:
            st.warning("å‹•ç”»ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸å¯")

    # 2. è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆï¼ˆèº«ä½“æ©Ÿèƒ½Ã—æ­©è¡Œçµ±åˆç‰ˆï¼‰
    st.header("ğŸ‘¨â€âš•ï¸ AIç†å­¦ç™‚æ³•å£«ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    
    input_data = {
        'pain': pain_areas,
        'toe_l': toe_grip_l, 'toe_r': toe_grip_r,
        'hip_l': hip_flex_l, 'hip_r': hip_flex_r,
        'ols_l': one_leg_l, 'ols_r': one_leg_r,
        'frt': frt, 'ffd': ffd, 'seat_step': seat_step
    }
    
    feedbacks = generate_clinical_feedback(input_data)
    
    for msg in feedbacks:
        st.info(msg)

    # 3. æ¨å¥¨é‹å‹• & ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ‹ï¸â€â™€ï¸ æ¨å¥¨é‹å‹• & ãƒ¬ãƒãƒ¼ãƒˆ")
    rec_col1, rec_col2 = st.columns([3, 1])
    
    with rec_col1:
        if (toe_grip_l + toe_grip_r)/2 < 15:
            st.markdown("- **è¶³æŒ‡å¼·åŒ–**: ã‚¿ã‚ªãƒ«ã‚®ãƒ£ã‚¶ãƒ¼ã€è¶³æŒ‡ã˜ã‚ƒã‚“ã‘ã‚“")
        if hip_flex_l < 1.0 or hip_flex_r < 1.0:
            st.markdown("- **è…¸è…°ç­‹å¼·åŒ–**: ãƒ‹ãƒ¼ã‚¢ãƒƒãƒ—ã€å¤§è‚¡æ­©ã")
        if one_leg_l < 20 or one_leg_r < 20:
            st.markdown("- **ä¸­æ®¿ç­‹ãƒ»ãƒãƒ©ãƒ³ã‚¹**: ç‰‡è„šç«‹ã¡ä¿æŒï¼ˆ1åˆ†é–“ï¼‰")
        if frt < 30:
            st.markdown("- **å‹•çš„ãƒãƒ©ãƒ³ã‚¹**: é‡å¿ƒç§»å‹•ç·´ç¿’")
            
    with rec_col2:
        # PDFç”Ÿæˆ
        pdf_data = create_pdf(client_name, input_data, feedbacks, main_metrics)
        st.download_button(
            label="ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆPDFã‚’DL",
            data=pdf_data,
            file_name=f"{client_name}_Analysis_Report.pdf",
            mime="application/pdf"
        )
        
        st.markdown("---") # åŒºåˆ‡ã‚Šç·š

        # 2. è§£æå‹•ç”»ã®DL
        if path_s: # å´é¢å‹•ç”»ãŒã‚ã‚‹å ´åˆ
            with open(path_s, 'rb') as v_file:
                st.download_button(
                    label="ğŸ¥ è§£æå‹•ç”» (å´é¢)ã‚’ä¿å­˜",
                    data=v_file,
                    file_name=f"{client_name}_SideView.mp4",
                    mime="video/mp4"
                )
        
        if path_f: # æ­£é¢å‹•ç”»ãŒã‚ã‚‹å ´åˆ
            with open(path_f, 'rb') as v_file:
                st.download_button(
                    label="ğŸ¥ è§£æå‹•ç”» (æ­£é¢)ã‚’ä¿å­˜",
                    data=v_file,
                    file_name=f"{client_name}_FrontView.mp4",
                    mime="video/mp4"
                )
