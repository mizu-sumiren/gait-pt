import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import io
import math
from PIL import Image

# --- PDFç”Ÿæˆç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ² (PDFç”¨) ---
# HeiseiKakuGo-W5 ã¯å¤šãã®PDFãƒªãƒ¼ãƒ€ãƒ¼ã§æ¨™æº–çš„ã«ä½¿ãˆã‚‹æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã§ã™
pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))

# --- MediaPipeåˆæœŸåŒ– ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIå§¿å‹¢ãƒ»æ­©è¡Œåˆ†æãƒ©ãƒœ", page_icon="ğŸ¥", layout="wide")

# --- CSSè¨­å®š (ãƒ¡ãƒ‹ãƒ¥ãƒ¼éè¡¨ç¤ºãªã©) ---
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            .stDeployButton {display:none;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¢ãƒ¼ãƒ‰é¸æŠ ---
st.sidebar.header("âš™ï¸ åˆ†æãƒ¢ãƒ¼ãƒ‰")
app_mode = st.sidebar.radio(
    "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)", "å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Lite)", "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ (ç«‹ä½/åº§ä½)"]
)

# --- ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º ---
if "æ­©è¡Œ" in app_mode:
    st.title("ğŸƒâ€â™‚ï¸ AIæ­©è¡Œãƒ‰ãƒƒã‚¯")
    st.markdown(f"ãƒ¢ãƒ¼ãƒ‰: {app_mode}")
else:
    st.title("ğŸ“¸ AIå§¿å‹¢åˆ†æãƒ©ãƒœ")
    st.markdown("æ­£é¢(ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ) Ã— å´é¢(çŒ«èƒŒãƒ»FHP) ã®åŒæ™‚è©•ä¾¡")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼å…¥åŠ› ---
st.sidebar.header("ğŸ“‹ å¯¾è±¡è€…æƒ…å ±")
client_name = st.sidebar.text_input("æ°å", "ãƒ†ã‚¹ãƒˆ å¤ªéƒ æ§˜")

# Proãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è©³ç´°å…¥åŠ› (è¡¨ç¤ºã®ã¿ã§ç¾åœ¨ã¯ãƒ­ã‚¸ãƒƒã‚¯ã«ã¯å½±éŸ¿ã—ã¾ã›ã‚“)
if app_mode == "å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)":
    with st.sidebar.expander("1. å•è¨ºãƒ»ç—›ã¿", expanded=True):
        pain_areas = st.multiselect("ç—›ã¿", ["ãªã—", "é¦–", "è‚©", "è…°", "è‚¡é–¢ç¯€", "è†", "è¶³é¦–"])
    with st.sidebar.expander("2. èº«ä½“æ©Ÿèƒ½æ¸¬å®š", expanded=True):
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**å·¦ (L)**")
            grip_l = st.number_input("æ¡åŠ›L", 20.0); hip_flex_l = st.number_input("è‚¡å±ˆæ›²L", 0.9)
        with c2:
            st.markdown("**å³ (R)**")
            grip_r = st.number_input("æ¡åŠ›R", 25.0); hip_flex_r = st.number_input("è‚¡å±ˆæ›²R", 1.2)

# --- å¹¾ä½•å­¦è¨ˆç®—é–¢æ•° ---
def calculate_angle(a, b, c):
    """3ç‚¹é–“ã®è§’åº¦ã‚’ç®—å‡º"""
    a, b, c = np.array(a), np.array(b), np.array(c)
    rad = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(rad*180.0/np.pi)
    if angle > 180.0: angle = 360-angle
    return angle

def calculate_slope(a, b):
    """2ç‚¹é–“ã®å‚¾ã"""
    if a is None or b is None: return 0
    return math.degrees(math.atan2(a[1]-b[1], a[0]-b[0]))

def calculate_vertical_angle(a, b):
    """å‚ç›´ç·šã«å¯¾ã™ã‚‹è§’åº¦"""
    if a is None or b is None: return 0
    return math.degrees(math.atan2(b[0]-a[0], b[1]-a[1]))

# --- é™æ­¢ç”»åˆ†æãƒ­ã‚¸ãƒƒã‚¯ ---
def analyze_static_image(image, view, posture_type):
    with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:
        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if not results.pose_landmarks: return image, None

        h, w, _ = image.shape
        lms = results.pose_landmarks.landmark
        annotated_image = image.copy()
        
        # ã‚°ãƒªãƒƒãƒ‰ç·š
        cv2.line(annotated_image, (w//2, 0), (w//2, h), (0, 255, 255), 2)
        mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        def get_p(idx): return [lms[idx].x * w, lms[idx].y * h]
        metrics = {}

        # --- A. æ­£é¢å†™çœŸã®åˆ†æ ---
        if view == "front":
            metrics['head_tilt'] = calculate_slope(get_p(7), get_p(8)) # è€³ã®å‚¾ã
            metrics['shoulder_slope'] = calculate_slope(get_p(11), get_p(12)) # è‚©ã®å‚¾ã
            metrics['hip_slope'] = calculate_slope(get_p(23), get_p(24)) # éª¨ç›¤

        # --- B. å´é¢å†™çœŸã®åˆ†æ ---
        elif view == "side":
            # ã‚¹ãƒãƒ›é¦– (è€³7ã¨è‚©11ã®Xå·®ã‚’ç”»åƒå¹…ã«å¯¾ã™ã‚‹%ã§)
            ear_x = (lms[7].x + lms[8].x) / 2 
            shoulder_x = (lms[11].x + lms[12].x) / 2
            metrics['forward_head_score'] = (ear_x - shoulder_x) * 100 
            
            # ä½“å¹¹ã®å‰å‚¾
            metrics['trunk_lean'] = calculate_vertical_angle(get_p(11), get_p(23))
            
            # è†ãƒ»è‚¡é–¢ç¯€
            if posture_type == "ç«‹ä½ (Standing)":
                metrics['knee_angle'] = calculate_angle(get_p(23), get_p(25), get_p(27))
            else: # åº§ä½
                metrics['hip_angle'] = calculate_angle(get_p(11), get_p(23), get_p(25))

        return annotated_image, metrics

# --- é™æ­¢ç”»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ ---
def generate_static_feedback(f_metrics, s_metrics, posture_type):
    fb = []
    
    # æ­£é¢
    if f_metrics:
        if abs(f_metrics['head_tilt']) > 3.0: fb.append("âš ï¸ ã€é ­éƒ¨ã®å‚¾ãã€‘ æ­£é¢ã‹ã‚‰è¦‹ã¦é¦–ãŒå‚¾ã„ã¦ã„ã¾ã™ã€‚")
        slope = f_metrics['shoulder_slope']
        if abs(slope) > 3.0: 
            side = "å³" if slope > 0 else "å·¦"
            fb.append(f"âš ï¸ ã€è‚©ã®é«˜ã•ã€‘ {side}è‚©ãŒä¸‹ãŒã£ã¦ã„ã¾ã™ã€‚")
    
    # å´é¢
    if s_metrics:
        if abs(s_metrics['forward_head_score']) > 5.0: 
            fb.append("âš ï¸ ã€ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãƒãƒƒã‚¯å‚¾å‘ã€‘ é ­ãŒè‚©ã‚ˆã‚Šå‰ã«å‡ºã¦ã„ã¾ã™ï¼ˆã‚¹ãƒãƒ›é¦–ï¼‰ã€‚")
        
        if abs(s_metrics['trunk_lean']) > 10: 
            fb.append("âš ï¸ ã€çŒ«èƒŒãƒ»åã‚Šè…°ã€‘ ä¸ŠåŠèº«ã®è»¸ãŒå‚ç›´ã‹ã‚‰å‚¾ã„ã¦ã„ã¾ã™ã€‚")

        if posture_type == "ç«‹ä½ (Standing)":
            if s_metrics.get('knee_angle', 180) < 165: fb.append("â„¹ï¸ ã€è†æ›²ãŒã‚Šã€‘ è†ãŒä¼¸ã³åˆ‡ã£ã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            if s_metrics.get('hip_angle', 90) > 110: fb.append("â„¹ï¸ ã€ä»™éª¨åº§ã‚Šã€‘ éª¨ç›¤ãŒå¾Œã‚ã«å€’ã‚Œã€è…°ã¸ã®è² æ‹…ãŒå¤§ãã„åº§ã‚Šæ–¹ã§ã™ã€‚")

    if not fb: fb.append("âœ… ã€Goodã€‘ éå¸¸ã«ç¶ºéº—ãªå§¿å‹¢ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã§ã™ã€‚")
    return fb

# --- å‹•ç”»åˆ†æé–¢æ•° (ä¿®æ­£ç‰ˆ) ---
def analyze_video_metrics(history, fps):
    if not history: return None
    dists = []
    # è¶³é¦–é–“è·é›¢ã‚’ç”¨ã„ãŸç°¡æ˜“æ­©æ•°ã‚«ã‚¦ãƒ³ãƒˆ
    for lms in history:
        la, ra = np.array([lms[27].x, lms[27].y]), np.array([lms[28].x, lms[28].y])
        dists.append(np.linalg.norm(la - ra))
    
    steps = 0
    if len(dists) > 0:
        thresh = np.mean(dists)
        for i in range(1, len(dists)-1):
            if dists[i] > dists[i-1] and dists[i] > dists[i+1] and dists[i] > thresh: 
                steps += 1
                
    duration = len(history) / fps
    cadence = (steps / duration) * 60 if duration > 0 else 0
    return {"cadence": cadence, "steps": steps}

def process_video(file):
    """å‹•ç”»å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•° (è‰²ä¿®æ­£ãƒ»æ•°å€¤æç”»è¿½åŠ æ¸ˆã¿)"""
    if not file: return None, None
    tfile = tempfile.NamedTemporaryFile(delete=False); tfile.write(file.read())
    cap = cv2.VideoCapture(tfile.name)
    w, h, fps = int(cap.get(3)), int(cap.get(4)), int(cap.get(5))
    path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
    history = []
    
    with mp_pose.Pose() as pose:
        while cap.isOpened():
            ret, img = cap.read()
            if not ret: break
            
            # 1. è§£æç”¨: BGR -> RGBå¤‰æ›
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_rgb.flags.writeable = False
            res = pose.process(img_rgb)
            
            # 2. æ›¸ãè¾¼ã¿ç”¨: img (BGRã®ã¾ã¾) ã‚’ä½¿ç”¨ â€»ã“ã“ãŒè‰²ä¿®æ­£ã®ãƒã‚¤ãƒ³ãƒˆ
            
            # ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
            cv2.line(img, (w//2,0), (w//2,h), (0,255,255), 1)
            
            if res.pose_landmarks:
                mp_drawing.draw_landmarks(img, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                lms = res.pose_landmarks.landmark
                history.append(lms)
                
                # --- PTè¦–ç‚¹: å³è†è§’åº¦ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨ˆç®—ã¨è¡¨ç¤º ---
                def get_c(idx): return [lms[idx].x * w, lms[idx].y * h]
                try:
                    # å³è‚¡é–¢ç¯€(24)-å³è†(26)-å³è¶³é¦–(28)
                    knee_angle = calculate_angle(get_c(24), get_c(26), get_c(28))
                    
                    # ç”»é¢å³ä¸Šã«è§’åº¦è¡¨ç¤ºãƒ‘ãƒãƒ«ã‚’æç”»
                    cv2.rectangle(img, (w-220, 0), (w, 60), (255, 255, 255), -1)
                    cv2.putText(img, f"R-Knee: {int(knee_angle)}", (w-200, 40), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                except:
                    pass

            out.write(img)
            
    cap.release(); out.release()
    return path, analyze_video_metrics(history, fps)

# --- PDFç”Ÿæˆ (ä¿®æ­£ç‰ˆãƒ»æ—¥æœ¬èªå¯¾å¿œ) ---
def create_pdf(title, name, feedbacks, vid=None, f_stat=None, s_stat=None):
    b = io.BytesIO()
    c = canvas.Canvas(b, pagesize=A4); h = A4[1]
    
    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š (HeiseiKakuGo-W5)
    font_name = "HeiseiKakuGo-W5"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    c.setFont(font_name, 18)
    c.drawString(50, h-50, f"åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {title}")
    c.setFont(font_name, 12)
    c.drawString(50, h-80, f"æ°å: {name}")
    c.setLineWidth(1)
    c.line(50, h-90, 550, h-90)
    
    y = h-130
    # --- ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    c.setFont(font_name, 14); c.drawString(50, y, "1. è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ (Metrics)")
    y -= 25; c.setFont(font_name, 11)
    
    if vid:
        c.drawString(60, y, f"ãƒ»ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ (æ­©è¡Œãƒªã‚ºãƒ ): {vid['cadence']:.1f} æ­©/åˆ†")
        y -= 20
        c.drawString(60, y, f"ãƒ»æ¤œå‡ºæ­©æ•°: {vid['steps']} æ­©")
        y -= 30
    
    if f_stat:
        c.drawString(60, y, "[æ­£é¢åˆ†æçµæœ]")
        y -= 20
        c.drawString(70, y, f"ãƒ»é ­éƒ¨ã®å‚¾ã: {f_stat['head_tilt']:.1f} åº¦")
        c.drawString(300, y, f"ãƒ»è‚©ã®å‚¾ã: {f_stat['shoulder_slope']:.1f} åº¦")
        y -= 30
        
    if s_stat:
        c.drawString(60, y, "[å´é¢åˆ†æçµæœ]")
        y -= 20
        c.drawString(70, y, f"ãƒ»FHPã‚¹ã‚³ã‚¢(é ­ã®å‰æ–¹åä½): {s_stat['forward_head_score']:.1f}")
        c.drawString(300, y, f"ãƒ»ä½“å¹¹å‰å‚¾è§’åº¦: {s_stat['trunk_lean']:.1f} åº¦")
        y -= 30

    y -= 20
    # --- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (æ—¥æœ¬èªå‡ºåŠ›å¯¾å¿œ) ---
    c.setFont(font_name, 14); c.drawString(50, y, "2. AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ & ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
    y -= 30; c.setFont(font_name, 11)
    
    for msg in feedbacks:
        # ç°¡æ˜“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        clean_msg = msg.replace("**", "")
        c.drawString(60, y, clean_msg)
        y -= 25
        if y < 50: # æ”¹ãƒšãƒ¼ã‚¸å‡¦ç†
            c.showPage()
            c.setFont(font_name, 11)
            y = h-50
            
    c.showPage(); c.save(); b.seek(0)
    return b

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# A. é™æ­¢ç”»åˆ†æãƒ¢ãƒ¼ãƒ‰
if app_mode == "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ (ç«‹ä½/åº§ä½)":
    st.info("ğŸ“¸ æ­£é¢ãƒ»å´é¢ãã‚Œãã‚Œã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆç‰‡æ–¹ã®ã¿ã‚‚å¯ï¼‰")
    posture_type = st.radio("å§¿å‹¢ã‚¿ã‚¤ãƒ—", ["ç«‹ä½ (Standing)", "åº§ä½ (Sitting)"], horizontal=True)
    
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("â‘  æ­£é¢å†™çœŸ")
        file_f = st.file_uploader("Front Image", type=['jpg','png','jpeg'], key="sf")
    with c2:
        st.subheader("â‘¡ å´é¢å†™çœŸ")
        file_s = st.file_uploader("Side Image", type=['jpg','png','jpeg'], key="ss")
    
    if st.button("ğŸš€ å§¿å‹¢åˆ†æã‚’å®Ÿè¡Œ"):
        f_img, f_met, s_img, s_met = None, None, None, None
        
        # 1. æ­£é¢åˆ†æ
        if file_f:
            img = np.array(Image.open(file_f))
            f_img, f_met = analyze_static_image(img, "front", posture_type)
        
        # 2. å´é¢åˆ†æ
        if file_s:
            img = np.array(Image.open(file_s))
            s_img, s_met = analyze_static_image(img, "side", posture_type)
            
        if f_met or s_met:
            # ç”»åƒè¡¨ç¤º
            col1, col2 = st.columns(2)
            with col1:
                if f_img is not None: st.image(f_img, caption="æ­£é¢è§£æ", use_container_width=True)
            with col2:
                if s_img is not None: st.image(s_img, caption="å´é¢è§£æ", use_container_width=True)

            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.subheader("ğŸ“Š ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè¨ˆæ¸¬å€¤")
            d1, d2 = st.columns(2)
            with d1:
                st.markdown("##### æ­£é¢ãƒ‡ãƒ¼ã‚¿")
                if f_met:
                    st.metric("é ­éƒ¨ã®å‚¾ã", f"{f_met['head_tilt']:.1f}Â°")
                    st.metric("è‚©ã®å‚¾ã", f"{f_met['shoulder_slope']:.1f}Â°")
                else: st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")
            with d2:
                st.markdown("##### å´é¢ãƒ‡ãƒ¼ã‚¿")
                if s_met:
                    st.metric("ä½“å¹¹å‰å‚¾", f"{s_met['trunk_lean']:.1f}Â°")
                    val = s_met.get('knee_angle') if posture_type == "ç«‹ä½ (Standing)" else s_met.get('hip_angle')
                    label = "è†ä¼¸å±•" if posture_type == "ç«‹ä½ (Standing)" else "è‚¡é–¢ç¯€å±ˆæ›²"
                    st.metric(label, f"{val:.1f}Â°")
                else: st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            st.header("ğŸ‘¨â€âš•ï¸ AIå§¿å‹¢ãƒ¬ãƒãƒ¼ãƒˆ")
            feedbacks = generate_static_feedback(f_met, s_met, posture_type)
            for msg in feedbacks:
                if "âš ï¸" in msg: st.error(msg)
                elif "â„¹ï¸" in msg: st.warning(msg)
                else: st.success(msg)

            # ä¿å­˜
            pdf = create_pdf("å§¿å‹¢åˆ†æ (Posture Analysis)", client_name, feedbacks, f_stat=f_met, s_stat=s_met)
            st.download_button("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ (PDF)", pdf, "posture_report.pdf", "application/pdf")
            
        else:
            st.warning("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

# B. å‹•ç”»åˆ†æãƒ¢ãƒ¼ãƒ‰
else:
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("â‘  æ­£é¢å‹•ç”»")
        file_f = st.file_uploader("Front Video", type=['mp4', 'mov'], key="vf")
    with c2:
        st.subheader("â‘¡ å´é¢å‹•ç”»")
        file_s = st.file_uploader("Side Video", type=['mp4', 'mov'], key="vs")

    if st.button("ğŸš€ æ­©è¡Œåˆ†æã‚’å®Ÿè¡Œ"):
        path_f, met_f = process_video(file_f)
        path_s, met_s = process_video(file_s)
        
        main_met = met_s if met_s else met_f
        
        st.markdown("---")
        c1, c2 = st.columns(2)
        with c1: 
            if path_f: st.video(path_f)
        with c2: 
            if path_s: st.video(path_s)

        if main_met:
            st.subheader("ğŸ“Š æ­©è¡Œãƒ‡ãƒ¼ã‚¿")
            st.metric("ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ (æ­©è¡Œç‡)", f"{main_met['cadence']:.1f} æ­©/åˆ†")
            st.info(f"æ¤œå‡ºæ­©æ•°: {main_met['steps']}æ­©")
            
            fb = ["âœ… è§£æå®Œäº†ã€‚è©³ç´°ã¯PDFã‚’ã”ç¢ºèªãã ã•ã„ã€‚"]
            if main_met['cadence'] < 100: fb.append("â„¹ï¸ æ­©è¡Œãƒšãƒ¼ã‚¹ãŒã‚„ã‚„ã‚†ã£ãã‚Šã§ã™ã€‚")
            if main_met['cadence'] > 120: fb.append("â„¹ï¸ æ—©æ­©ãå‚¾å‘ã€ã¾ãŸã¯å°åˆ»ã¿æ­©è¡Œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            
            # PDFç”¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            pdf_fb = fb
            
            pdf = create_pdf("æ­©è¡Œåˆ†æ (Gait Analysis)", client_name, pdf_fb, vid=main_met)
            st.download_button("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ (PDF)", pdf, "gait_report.pdf", "application/pdf")
