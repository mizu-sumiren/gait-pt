import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import io
import math
from datetime import datetime
from PIL import Image

from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.lib.utils import ImageReader

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²
pdfmetrics.registerFont(UnicodeCIDFont("HeiseiKakuGo-W5"))

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

st.set_page_config(page_title="AIå§¿å‹¢ãƒ»æ­©è¡Œåˆ†æãƒ©ãƒœ", page_icon="ğŸ¥", layout="wide")

hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
.stDeployButton {display:none;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.sidebar.header("âš™ï¸ åˆ†æãƒ¢ãƒ¼ãƒ‰")
app_mode = st.sidebar.radio(
    "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)", "å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Lite)", "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ (ç«‹ä½/åº§ä½)"]
)

if "æ­©è¡Œ" in app_mode:
    st.title("ğŸƒâ€â™‚ï¸ AIæ­©è¡Œãƒ‰ãƒƒã‚¯ (Clinical Grade)")
    st.caption("è»¢å€’ãƒªã‚¹ã‚¯ãƒ»è…°ç—›ãƒªã‚¹ã‚¯ã‚’ã€Œæºã‚Œã€ã€Œã°ã‚‰ã¤ãã€ã€Œå·¦å³å·®ã€ã‹ã‚‰å¯è¦–åŒ–")
else:
    st.title("ğŸ“¸ AIå§¿å‹¢åˆ†æãƒ©ãƒœ")
    st.caption("æ­£é¢(ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ) Ã— å´é¢(çŒ«èƒŒãƒ»FHP) ã®åŒæ™‚è©•ä¾¡")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
st.sidebar.header("ğŸ“‹ å¯¾è±¡è€…æƒ…å ±")
client_name = st.sidebar.text_input("æ°å", "ãƒ†ã‚¹ãƒˆ å¤ªéƒ æ§˜")
client_age = st.sidebar.number_input("å¹´é½¢", min_value=1, max_value=120, value=45, step=1)
client_gender = st.sidebar.selectbox("æ€§åˆ¥", ["ç”·æ€§", "å¥³æ€§", "ãã®ä»–"])
client_height_cm = st.sidebar.number_input("èº«é•· (cm)", min_value=100, max_value=250, value=170, step=1)

if app_mode == "å‹•ç”»ï¼šæ­©è¡Œåˆ†æ (Pro)":
    with st.sidebar.expander("1. å•è¨ºãƒ»ç—›ã¿", expanded=True):
        pain_areas = st.multiselect("ç—›ã¿", ["ãªã—", "é¦–", "è‚©", "è…°", "è‚¡é–¢ç¯€", "è†", "è¶³é¦–"])
else:
    pain_areas = []

# --- è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ ---

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    rad = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(rad * 180.0 / np.pi)
    if angle > 180.0:
        angle = 360 - angle
    return angle

def calculate_slope(a, b):
    if a is None or b is None:
        return 0.0
    return math.degrees(math.atan2(a[1]-b[1], a[0]-b[0]))

def calculate_vertical_angle(a, b):
    if a is None or b is None:
        return 0.0
    return math.degrees(math.atan2(b[0]-a[0], b[1]-a[1]))

def get_risk_stars(cv_score, sway_score, asymmetry_percent, age):
    risk_score = 0.0
    cv_threshold = 0.08 if age >= 65 else 0.05
    sway_threshold = 0.12 if age >= 65 else 0.08

    if cv_score > cv_threshold * 1.5: risk_score += 2
    elif cv_score > cv_threshold: risk_score += 1

    if sway_score > sway_threshold * 1.5: risk_score += 2
    elif sway_score > sway_threshold: risk_score += 1

    if asymmetry_percent > 15: risk_score += 2
    elif asymmetry_percent > 8: risk_score += 1

    if age >= 75: risk_score += 1
    elif age >= 65: risk_score += 0.5

    if risk_score >= 5: return "â˜…â˜†â˜†â˜†â˜† é«˜ãƒªã‚¹ã‚¯", 1
    elif risk_score >= 3.5: return "â˜…â˜…â˜†â˜†â˜† è¦æ³¨æ„", 2
    elif risk_score >= 2: return "â˜…â˜…â˜…â˜†â˜† ã‚„ã‚„æ³¨æ„", 3
    elif risk_score >= 1: return "â˜…â˜…â˜…â˜…â˜† è‰¯å¥½", 4
    else: return "â˜…â˜…â˜…â˜…â˜… å„ªè‰¯", 5

def generate_clinical_feedback(metrics, analysis_type="gait", age=45):
    fb_list = []
    exercises = []

    if analysis_type == "gait":
        cadence = metrics.get("cadence", 0.0)
        sway_score = metrics.get("sway_score", 0.0)
        cv_score = metrics.get("cv_score", 0.0)
        trunk_lean_mean = metrics.get("trunk_lean_mean", 0.0)
        asymmetry_percent = metrics.get("asymmetry_percent", 0.0)
        right_mean = metrics.get("right_step_mean", 0.0)
        left_mean = metrics.get("left_step_mean", 0.0)
        gait_speed = metrics.get("gait_speed_m_s", 0.0)

        cv_threshold = 0.08 if age >= 65 else 0.05
        sway_threshold = 0.12 if age >= 65 else 0.08

        if cadence < 95:
            fb_list.append({
                "title": "æ­©è¡Œãƒªã‚ºãƒ ã®ä½ä¸‹",
                "detail": f"æ­©è¡Œãƒšãƒ¼ã‚¹ãŒã‚†ã£ãã‚Šã§ã™ï¼ˆCadence: {cadence:.1f}æ­©/åˆ†ï¼‰ã€‚",
                "cause": "ä¸‹è‚¢ç­‹åŠ›ä½ä¸‹ã‚„è»¢å€’ä¸å®‰ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            })
            exercises.append("æ¤…å­åº§ã‚Šç«‹ã¡ (ä¸‹è‚¢ç­‹åŠ›å¼·åŒ–)")
        
        if cv_score > cv_threshold:
            fb_list.append({
                "title": "æ­©è¡Œå‘¨æœŸã®ã°ã‚‰ã¤ã",
                "detail": f"ä¸€æ­©ã”ã¨ã®ãƒªã‚ºãƒ ãŒä¸€å®šã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆCV: {cv_score:.3f}ï¼‰ã€‚",
                "cause": "é‹å‹•åˆ¶å¾¡èƒ½åŠ›ã®ä½ä¸‹ã‚„æ³¨æ„æ©Ÿèƒ½ã®åˆ†æ•£ã€‚",
                "priority": True
            })
            exercises.append("ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ æ­©è¡Œ")

        if sway_score > sway_threshold:
            fb_list.append({
                "title": "éª¨ç›¤ã®å‹•æºï¼ˆä½“å¹¹ä¸å®‰å®šï¼‰",
                "detail": f"éª¨ç›¤ã®å·¦å³ã¸ã®æºã‚ŒãŒå¤§ãã„ã§ã™ï¼ˆSway: {sway_score:.3f}ï¼‰ã€‚",
                "cause": "ä¸­æ®¿ç­‹ã‚„ä½“å¹¹ç­‹ã®å‡ºåŠ›ä¸è¶³ã€‚",
                "priority": True
            })
            exercises.append("ã‚µã‚¤ãƒ‰ãƒ¬ãƒƒã‚°ãƒ¬ã‚¤ã‚º")
            exercises.append("ãƒ—ãƒ©ãƒ³ã‚¯")

        if asymmetry_percent > 8:
            dominant = "å³" if right_mean > left_mean else "å·¦"
            fb_list.append({
                "title": "å·¦å³éå¯¾ç§°æ€§",
                "detail": f"{dominant}è¶³ã®æ»ç©ºæ™‚é–“ãŒé•·ãã€å·¦å³å·®ãŒã‚ã‚Šã¾ã™ï¼ˆ{asymmetry_percent:.1f}%ï¼‰ã€‚",
                "cause": "ç‰‡å´ã®ç–¼ç—›å›é¿ã‚„ç­‹åŠ›å·®ã€‚",
                "priority": asymmetry_percent > 15
            })
            exercises.append("ç‰‡è„šç«‹ã¡ç·´ç¿’")

        if not fb_list:
            fb_list.append({"title": "è‰¯å¥½ãªæ­©è¡Œ", "detail": "å•é¡Œã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã€‚", "cause": "ç¾çŠ¶ç¶­æŒæ¨å¥¨ã€‚"})

    else:
        # å§¿å‹¢åˆ†æç”¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆçœç•¥ãªã—ã§å®Ÿè£…ï¼‰
        s_met = metrics.get("s_met") or {}
        if abs(s_met.get("forward_head_score", 0.0)) > 5.0:
            fb_list.append({"title": "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãƒãƒƒã‚¯å‚¾å‘", "detail": "é ­éƒ¨å‰æ–¹åä½ã‚ã‚Šã€‚", "cause": "ã‚¹ãƒãƒ›é¦–ãªã©ã€‚"})
            exercises.append("ãƒãƒ³ã‚¤ãƒ³")

    return fb_list, list(set(exercises))

# --- ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆ æ­©è¡Œè§£æãƒ­ã‚¸ãƒƒã‚¯ ---

def analyze_gait_data_only(lms_history, fps, w, h, height_cm):
    # ç”»åƒã‚’ä½¿ã‚ãšã€åº§æ¨™ãƒ‡ãƒ¼ã‚¿(lms)ã ã‘ã§è¨ˆç®—ã™ã‚‹
    if not lms_history or fps <= 0:
        return {}, {}

    left_ankle_y = []
    right_ankle_y = []
    pelvis_sway = []
    trunk_lean_list = []
    hip_dists = []

    max_ml_abs = 0.0
    max_lean_abs = 0.0
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã®å¤‰æ•°
    idx_ml = 0
    idx_lean = 0
    idx_mid = len(lms_history) // 2

    for i, lms in enumerate(lms_history):
        # åº§æ¨™å–å¾— (æ­£è¦åŒ–åº§æ¨™)
        la_y = lms[27].y
        ra_y = lms[28].y
        left_ankle_y.append(la_y)
        right_ankle_y.append(ra_y)

        # Sway
        pm_x = (lms[23].x + lms[24].x) / 2.0
        pelvis_sway.append(pm_x)

        # Lean
        mid_s = [(lms[11].x + lms[12].x)/2 * w, (lms[11].y + lms[12].y)/2 * h]
        mid_h = [(lms[23].x + lms[24].x)/2 * w, (lms[23].y + lms[24].y)/2 * h]
        lean = calculate_vertical_angle(mid_h, mid_s)
        trunk_lean_list.append(lean)

        # ML Deviation logic
        trunk_cx = (pm_x * w + (lms[11].x + lms[12].x)/2 * w) / 2.0
        ml_dev = (trunk_cx - w/2.0) / (w/2.0)
        
        if abs(ml_dev) > max_ml_abs:
            max_ml_abs = abs(ml_dev)
            idx_ml = i
        
        if abs(lean) > max_lean_abs:
            max_lean_abs = abs(lean)
            idx_lean = i
            
        # Gait Speed calc components
        hl = np.array([lms[23].x*w, lms[23].y*h])
        hr = np.array([lms[24].x*w, lms[24].y*h])
        hip_dists.append(np.linalg.norm(hl - hr))

    # Step Detection
    def detect_steps(arr):
        steps = 0
        frames = []
        if len(arr) > 2:
            th = np.percentile(arr, 60)
            for i in range(1, len(arr)-1):
                if arr[i] > arr[i-1] and arr[i] > arr[i+1] and arr[i] > th:
                    steps += 1
                    frames.append(i)
        return steps, frames

    ls, lf = detect_steps(left_ankle_y)
    rs, rf = detect_steps(right_ankle_y)
    total_steps = ls + rs
    duration = len(lms_history) / fps
    cadence = (total_steps / duration) * 60 if duration > 0 else 0

    # Metrics
    asym = 0.0
    lm, rm = 0.0, 0.0
    if len(lf) > 1: lm = float(np.mean(np.diff(lf)))
    if len(rf) > 1: rm = float(np.mean(np.diff(rf)))
    if (lm+rm) > 0:
        asym = abs(lm - rm) / ((lm+rm)/2) * 100

    cv = 0.0
    all_f = sorted(lf + rf)
    if len(all_f) > 2:
        intervals = np.diff(all_f)
        if np.mean(intervals) > 0:
            cv = np.std(intervals) / np.mean(intervals)

    sway_score = float(np.std(pelvis_sway)) if pelvis_sway else 0
    lean_mean = float(np.mean(trunk_lean_list)) if trunk_lean_list else 0
    
    speed = 0.0
    if total_steps > 1 and cadence > 0:
        stride = height_cm * 0.01 * 0.45
        speed = (cadence/60) * stride

    metrics = {
        "cadence": cadence,
        "steps": total_steps,
        "cv_score": cv,
        "sway_score": sway_score,
        "trunk_lean_mean": lean_mean,
        "asymmetry_percent": asym,
        "left_step_mean": lm,
        "right_step_mean": rm,
        "gait_speed_m_s": speed
    }
    
    # é‡è¦ãªãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’è¿”ã™
    target_indices = {
        "mid": idx_mid,
        "ml": idx_ml,
        "lean": idx_lean
    }
    
    return metrics, target_indices

def process_video_optimized(file, height_cm):
    if not file: return None, None, None
    
    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(file.read())
    
    cap = cv2.VideoCapture(tfile.name)
    w = int(cap.get(3))
    h = int(cap.get(4))
    fps = int(cap.get(5))
    
    # 2. è§£æç”¨ãƒ‘ã‚¹ (ç”»åƒã¯ä¿å­˜ã›ãšã€åº§æ¨™ã®ã¿è¨˜éŒ²)
    lms_history = []
    
    # å‡ºåŠ›å‹•ç”»ç”¨ (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿ã§ãƒ¡ãƒ¢ãƒªç¯€ç´„)
    out_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
    # mp4vãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯ä»Šå›è€ƒãˆãªã„ï¼ˆpackages.txtã§å¯¾å¿œæ¸ˆã¿å‰æï¼‰
    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
    
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, img = cap.read()
            if not ret: break
            
            # MediaPipeå‡¦ç†
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_rgb.flags.writeable = False
            res = pose.process(img_rgb)
            
            # æç”»
            cv2.line(img, (w//2, 0), (w//2, h), (0, 255, 255), 1)
            if res.pose_landmarks:
                mp_drawing.draw_landmarks(img, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                # â˜…ã“ã“ã§ç”»åƒã¯ä¿å­˜ã›ãšã€åº§æ¨™ã ã‘ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹
                lms_history.append(res.pose_landmarks.landmark)
            else:
                lms_history.append(None) # æ¤œå‡ºãªã—ãƒ•ãƒ¬ãƒ¼ãƒ 
            
            out.write(img)
            
    cap.release()
    out.release()
    
    # 3. æ•°å€¤è§£æ & ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹å®š
    # Noneã‚’é™¤å»ã—ã¦è§£æã«å›ã™
    clean_lms = [l for l in lms_history if l is not None]
    if not clean_lms:
        return None, {}, {}
        
    metrics, target_indices = analyze_gait_data_only(clean_lms, fps, w, h, height_cm)
    
    # 4. ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã ã‘ã‚’å†å–å¾— (çœãƒ¡ãƒ¢ãƒª)
    snapshots = {}
    cap = cv2.VideoCapture(tfile.name) # å†ã‚ªãƒ¼ãƒ—ãƒ³
    
    for key, idx in target_indices.items():
        # idxç•ªç›®ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¸ã‚¸ãƒ£ãƒ³ãƒ—
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            # æç”»ç­‰ã¯çœç•¥ã—ã€ç”Ÿã®ç”»åƒã‚’ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã¨ã™ã‚‹
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            snapshots[key] = Image.fromarray(frame_rgb)
        else:
            snapshots[key] = None
            
    cap.release()
    
    return out_path, metrics, snapshots

def analyze_static_image(image, view, posture_type):
    # é™æ­¢ç”»æ©Ÿèƒ½ã¯å¤‰æ›´ãªã—
    with mp_pose.Pose(static_image_mode=True) as pose:
        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if not results.pose_landmarks: return image, {}
        h, w, _ = image.shape
        lms = results.pose_landmarks.landmark
        annotated = image.copy()
        mp_drawing.draw_landmarks(annotated, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        def gp(i): return [lms[i].x*w, lms[i].y*h]
        metrics = {}
        if view == "front":
            metrics["head_tilt"] = calculate_slope(gp(7), gp(8))
            metrics["shoulder_slope"] = calculate_slope(gp(11), gp(12))
        elif view == "side":
            metrics["forward_head_score"] = (lms[7].x - lms[11].x)*100
        return annotated, metrics

def create_comprehensive_pdf(title, name, fb_data, exercises, metrics_data, snapshots=None):
    if snapshots is None: snapshots = {}
    buf = io.BytesIO()
    c = canvas.Canvas(buf, pagesize=A4)
    pw, ph = A4
    font = "HeiseiKakuGo-W5"
    
    c.setFont(font, 18)
    c.drawString(40, ph-50, title)
    c.setFont(font, 11)
    c.drawString(40, ph-75, f"æ°å: {name}  /  åˆ¤å®šæ—¥: {datetime.now().strftime('%Y/%m/%d')}")
    c.line(40, ph-85, pw-40, ph-85)
    
    y = ph - 120
    # ç”»åƒé…ç½®
    if snapshots:
        x_pos = pw - 220
        for label in ["mid", "ml", "lean"]:
            img = snapshots.get(label)
            if img:
                ih = 100
                iw = ih * img.width / img.height
                c.drawImage(ImageReader(img), x_pos, y-ih, width=iw, height=ih)
                c.drawString(x_pos, y-ih-10, f"â–² {label}")
                y -= (ih + 30)

    c.setFont(font, 14)
    c.drawString(40, ph-120, "â–  åˆ†æçµæœ")
    y_text = ph - 145
    c.setFont(font, 10)
    
    if "cadence" in metrics_data:
        items = [
            f"Cadence: {metrics_data['cadence']:.1f} step/min",
            f"Speed: {metrics_data['gait_speed_m_s']:.2f} m/s",
            f"CV: {metrics_data['cv_score']:.3f}",
            f"Sway: {metrics_data['sway_score']:.3f}",
            f"Asymmetry: {metrics_data['asymmetry_percent']:.1f}%"
        ]
        for t in items:
            c.drawString(50, y_text, t)
            y_text -= 15
            
        star, _ = get_risk_stars(metrics_data['cv_score'], metrics_data['sway_score'], metrics_data['asymmetry_percent'], client_age)
        c.setFont(font, 12)
        c.drawString(50, y_text-10, f"â˜… ç·åˆè©•ä¾¡: {star}")
        y_text -= 40
    
    c.setFont(font, 14)
    c.drawString(40, y_text, "â–  ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    y_text -= 20
    c.setFont(font, 10)
    for fb in fb_data:
        c.drawString(50, y_text, f"â— {fb['title']}")
        c.drawString(60, y_text-15, f"çŠ¶æ…‹: {fb['detail']}")
        y_text -= 40
        
    c.showPage()
    c.save()
    buf.seek(0)
    return buf

# --- ãƒ¡ã‚¤ãƒ³UI ---

if app_mode == "é™æ­¢ç”»ï¼šå§¿å‹¢åˆ†æ (ç«‹ä½/åº§ä½)":
    st.info("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    f_file = st.file_uploader("æ­£é¢", type=["jpg","png"])
    s_file = st.file_uploader("å´é¢", type=["jpg","png"])
    if st.button("åˆ†æå®Ÿè¡Œ") and f_file and s_file:
        f_img = np.array(Image.open(f_file))
        s_img = np.array(Image.open(s_file))
        res_f, met_f = analyze_static_image(f_img, "front", "standing")
        res_s, met_s = analyze_static_image(s_img, "side", "standing")
        
        c1, c2 = st.columns(2)
        c1.image(res_f, caption="æ­£é¢")
        c2.image(res_s, caption="å´é¢")
        
        fb, ex = generate_clinical_feedback({"s_met": met_s}, "static", client_age)
        st.write(fb)
        
        pdf = create_comprehensive_pdf("å§¿å‹¢ãƒ¬ãƒãƒ¼ãƒˆ", client_name, fb, ex, {}, {})
        st.download_button("PDFä¿å­˜", pdf, "report.pdf")

else:
    st.info("ğŸ¥ æ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (30ç§’ä»¥å†…ã®å‹•ç”»æ¨å¥¨)")
    video_file = st.file_uploader("æ­©è¡Œå‹•ç”»", type=["mp4", "mov"])

    if st.button("ğŸš€ æ­©è¡Œåˆ†æã‚’å®Ÿè¡Œ") and video_file:
        with st.spinner("AIãŒå‹•ç”»ã‚’è§£æä¸­... (å®Œäº†ã¾ã§ãŠå¾…ã¡ãã ã•ã„)"):
            out_path, metrics, snapshots = process_video_optimized(video_file, client_height_cm)

        if out_path and metrics:
            st.video(out_path)
            
            c1, c2, c3 = st.columns(3)
            c1.metric("Cadence", f"{metrics['cadence']:.1f}")
            c2.metric("Sway", f"{metrics['sway_score']:.3f}")
            c3.metric("CV", f"{metrics['cv_score']:.3f}")
            
            star, _ = get_risk_stars(metrics['cv_score'], metrics['sway_score'], metrics['asymmetry_percent'], client_age)
            st.subheader(f"ç·åˆè©•ä¾¡: {star}")
            
            fb_data, ex_list = generate_clinical_feedback(metrics, "gait", client_age)
            for item in fb_data:
                st.info(f"**{item['title']}**: {item['detail']}")
            
            if ex_list:
                st.success(f"æ¨å¥¨é‹å‹•: {', '.join(ex_list)}")
                
            pdf = create_comprehensive_pdf("æ­©è¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ", client_name, fb_data, ex_list, metrics, snapshots)
            st.download_button("ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆä¿å­˜", pdf, "gait_report.pdf", "application/pdf")
        else:
            st.error("è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‹•ç”»ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
