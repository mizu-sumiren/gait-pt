import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import io
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import os

# --- MediaPipeåˆæœŸåŒ– ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="çµ±åˆæ­©è¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ (PT Pro)", page_icon="ğŸ›¡ï¸", layout="wide")

st.title("ğŸ›¡ï¸ çµ±åˆæ­©è¡Œãƒ»èº«ä½“æ©Ÿèƒ½åˆ†æãƒ¬ãƒãƒ¼ãƒˆ v2.0")
st.markdown("èº«ä½“æ©Ÿèƒ½è©•ä¾¡ Ã— AIæ­©è¡Œåˆ†æ Ã— è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè©³ç´°ãªæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯ ---
st.sidebar.header("ğŸ“‹ æ¸¬å®šãƒ‡ãƒ¼ã‚¿å…¥åŠ›")

with st.sidebar.expander("1. åŸºæœ¬æƒ…å ±ãƒ»å•è¨º", expanded=True):
    client_name = st.text_input("æ°å", "ãƒ†ã‚¹ãƒˆ å¤ªéƒ æ§˜") # ãƒ¬ãƒãƒ¼ãƒˆç”¨ã«è¿½åŠ 
    pain_areas = st.multiselect(
        "ç—›ã¿ãƒ»é•å’Œæ„Ÿã®ã‚ã‚‹éƒ¨ä½",
        ["ç‰¹ã«ãªã—", "é¦–", "è‚©", "è…°", "è‚¡é–¢ç¯€(å³)", "è‚¡é–¢ç¯€(å·¦)", "è†(å³)", "è†(å·¦)", "è¶³é¦–ãƒ»è¶³éƒ¨"]
    )

with st.sidebar.expander("2. æ©Ÿèƒ½æ¸¬å®šçµæœ", expanded=True):
    st.caption("å¯¾è±¡è€…ã®æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    col_s1, col_s2 = st.columns(2)
    with col_s1:
        st.markdown("**å·¦å´ (Left)**")
        grip_l = st.number_input("æ¡åŠ›(å·¦) kg", value=20.0)
        hip_flex_l = st.number_input("è‚¡å±ˆæ›²(å·¦) kgf/kg", value=0.9)
        one_leg_l = st.number_input("ç‰‡è„šç«‹ä½(å·¦) ç§’", value=15.0)
        toe_grip_l = st.number_input("è¶³è¶¾æŠŠæŒ(å·¦) %", value=10.0)
    with col_s2:
        st.markdown("**å³å´ (Right)**")
        grip_r = st.number_input("æ¡åŠ›(å³) kg", value=25.0)
        hip_flex_r = st.number_input("è‚¡å±ˆæ›²(å³) kgf/kg", value=1.2)
        one_leg_r = st.number_input("ç‰‡è„šç«‹ä½(å³) ç§’", value=60.0)
        toe_grip_r = st.number_input("è¶³è¶¾æŠŠæŒ(å³) %", value=20.0)

    st.markdown("---")
    frt = st.number_input("FRT (cm)", value=25.0)
    ffd = st.number_input("FFD (cm)", value=0.0)
    seat_step = st.number_input("åº§ä½ã‚¹ãƒ†ãƒƒãƒ— (å›/20ç§’)", value=30)

# --- é–¢æ•°ï¼šæ­©è¡ŒæŒ‡æ¨™ï¼ˆã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ãƒ»æ­©å¹…ï¼‰ã®è¨ˆç®— ---
def analyze_gait_metrics(landmarks_history, fps):
    """
    å‹•ç”»å…¨ä½“ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å±¥æ­´ã‹ã‚‰æ­©æ•°ã€ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ã€æ­©å¹…æ¯”ç‡ã‚’ç®—å‡º
    """
    if not landmarks_history:
        return None

    # è¶³é¦–é–“ã®è·é›¢ï¼ˆXè»¸æ–¹å‘ã®å·®åˆ†ï¼‰ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    # Left Ankle: 27, Right Ankle: 28
    ankle_distances = []
    
    # æ­£è¦åŒ–ã®ãŸã‚ã®ä¸‹è…¿é•·ï¼ˆè†25-è¶³é¦–27ï¼‰ã®å¹³å‡ã‚µã‚¤ã‚ºã‚’å–å¾—ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«è£œæ­£ç”¨ï¼‰
    shin_lengths = []

    for lms in landmarks_history:
        # åº§æ¨™å–å¾— (MediaPipeã¯æ­£è¦åŒ–åº§æ¨™ 0.0-1.0 ãªã®ã§ãã®ã¾ã¾è·é›¢è¨ˆç®—å¯)
        la = np.array([lms[27].x, lms[27].y])
        ra = np.array([lms[28].x, lms[28].y])
        lk = np.array([lms[25].x, lms[25].y])
        
        # è¶³é¦–é–“è·é›¢ (æ­©å¹…ã®æŒ‡æ¨™)
        dist = np.linalg.norm(la - ra)
        ankle_distances.append(dist)
        
        # ä¸‹è…¿é•· (å·¦è„šã§ä»£è¡¨)
        shin_len = np.linalg.norm(lk - la)
        shin_lengths.append(shin_len)

    # 1. æ­©æ•°ã‚«ã‚¦ãƒ³ãƒˆï¼ˆè·é›¢ã®æ¥µå¤§å€¤ã‚’æ¤œå‡ºï¼‰
    # ç°¡æ˜“çš„ãªãƒ”ãƒ¼ã‚¯æ¤œå‡º: å‰å¾Œã‚ˆã‚Šå€¤ãŒå¤§ãã„ç‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    steps = 0
    peaks = []
    threshold = np.mean(ankle_distances) # å¹³å‡ä»¥ä¸Šã®åºƒãŒã‚Šã‚’å¯¾è±¡
    
    for i in range(1, len(ankle_distances)-1):
        prev = ankle_distances[i-1]
        curr = ankle_distances[i]
        nex = ankle_distances[i+1]
        if curr > prev and curr > nex and curr > threshold:
            steps += 1
            peaks.append(curr)

    # 2. æ™‚é–“è¨ˆç®—
    duration_sec = len(landmarks_history) / fps
    
    # 3. ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ (æ­©/åˆ†)
    cadence = (steps / duration_sec) * 60 if duration_sec > 0 else 0
    
    # 4. å¹³å‡æ­©å¹…ï¼ˆæ­£è¦åŒ–å€¤: æ­©å¹… / ä¸‹è…¿é•·ï¼‰
    # ã“ã‚Œã«ã‚ˆã‚Šã€ã‚«ãƒ¡ãƒ©ã®è·é›¢ã«é–¢ä¿‚ãªãã€Œè„šã®é•·ã•ã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„é–‹ã„ã¦ã„ã‚‹ã‹ã€ãŒã‚ã‹ã‚‹
    avg_step_pixel = np.mean(peaks) if peaks else 0
    avg_shin_pixel = np.mean(shin_lengths) if shin_lengths else 1
    normalized_step_length = avg_step_pixel / avg_shin_pixel

    return {
        "steps": steps,
        "duration": duration_sec,
        "cadence": cadence,
        "step_ratio": normalized_step_length
    }

# --- é–¢æ•°ï¼šPDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ---
def create_pdf(client_name, data, feedbacks, gait_metrics):
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4

    # --- ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ---
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆç’°å¢ƒã«ã‚ˆã£ã¦ãƒ‘ã‚¹ãŒé•ã†ãŸã‚ã€ã‚¨ãƒ©ãƒ¼å›é¿ç”¨ã®Try-Exceptï¼‰
    # æ‰‹å…ƒã« .ttf (ä¾‹: IPAexGothic.ttf) ãŒã‚ã‚Œã°ãã‚Œã‚’èª­ã¿è¾¼ã‚€ã®ãŒç¢ºå®Ÿã§ã™
    try:
        # Streamlit Cloudç­‰ã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã«åˆ¶é™ãŒã‚ã‚‹ãŸã‚ã€ã“ã“ã§ã¯è‹±èªãƒ•ã‚©ãƒ³ãƒˆã‚’åŸºæœ¬ã«ã—ã¤ã¤
        # å¯èƒ½ãªã‚‰æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æŒ‡å®šã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆâ€»å®Ÿé‹ç”¨æ™‚ã¯ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæ¢±æ¨å¥¨ï¼‰
        # ä»Šå›ã¯ãƒ‡ãƒ¢ã®ãŸã‚ã€æ¨™æº–ã®Helveticaã‚’ä½¿ã„ã¾ã™ãŒã€æ—¥æœ¬èªã¯æ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        # â˜…å®Ÿé‹ç”¨ï¼šåŒéšå±¤ã« 'IPAexGothic.ttf' ã‚’ç½®ã„ã¦ä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦ãã ã•ã„
        # pdfmetrics.registerFont(TTFont('Japanese', 'IPAexGothic.ttf'))
        # c.setFont('Japanese', 12)
        c.setFont("Helvetica-Bold", 16)
        c.drawString(50, height - 50, f"Gait & Physical Analysis Report")
        c.setFont("Helvetica", 10)
        c.drawString(50, height - 70, "Note: To display Japanese correctly, a .ttf font file is required on the server.")
    except:
        c.setFont("Helvetica-Bold", 16)
        c.drawString(50, height - 50, "Analysis Report")

    # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
    y = height - 100
    c.setFont("Helvetica", 12)
    c.drawString(50, y, f"Name: {client_name}")
    y -= 20
    c.drawString(50, y, f"Date: 2025/12/02") # æœ¬æ¥ã¯ datetime.now()
    
    # æ­©è¡Œåˆ†æãƒ‡ãƒ¼ã‚¿ (Gait Metrics)
    y -= 40
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, y, "1. Gait Analysis (AI Video)")
    y -= 20
    c.setFont("Helvetica", 11)
    if gait_metrics:
        c.drawString(60, y, f"Cadence: {gait_metrics['cadence']:.1f} steps/min")
        c.drawString(250, y, f"Step Ratio: {gait_metrics['step_ratio']:.2f} (Step/Leg Length)")
    else:
        c.drawString(60, y, "No video data analyzed.")

    # æ©Ÿèƒ½è©•ä¾¡ãƒ‡ãƒ¼ã‚¿
    y -= 40
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, y, "2. Physical Functions")
    y -= 20
    c.setFont("Helvetica", 11)
    c.drawString(60, y, f"Toe Grip: L {data['toe_l']}% / R {data['toe_r']}%")
    c.drawString(250, y, f"One Leg Stand: L {data['ols_l']}s / R {data['ols_r']}s")
    y -= 20
    c.drawString(60, y, f"Hip Flexion: L {data['hip_l']} / R {data['hip_r']}")
    c.drawString(250, y, f"FRT: {data['frt']}cm  /  FFD: {data['ffd']}cm")

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    y -= 40
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, y, "3. AI PT Feedback")
    c.setFont("Helvetica", 10)
    y -= 20
    
    # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’PDFã«å…¥ã‚Œã‚‹ã®ã¯ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šãªã—ã§ã¯é›£ã—ã„ãŸã‚ã€
    # ç°¡æ˜“çš„ã«è‹±èªã‹ãƒ­ãƒ¼ãƒå­—ã€ã‚ã‚‹ã„ã¯ã€ŒWebç”»é¢ã‚’å‚ç…§ã€ã¨ã™ã‚‹ã®ãŒåˆæœŸæ®µéšã§ã¯å®‰å…¨ã§ã™ã€‚
    c.drawString(60, y, "Please refer to the application screen for detailed Japanese feedback.")
    c.drawString(60, y-15, "(Japanese font configuration is needed for full text PDF)")

    # å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆæµã—è¾¼ã¿ï¼ˆãƒ•ã‚©ãƒ³ãƒˆãŒã‚ã‚‹å‰æï¼‰
    # for msg in feedbacks:
    #     y -= 20
    #     c.drawString(60, y, f"- {msg[:40]}...") 

    c.showPage()
    c.save()
    buffer.seek(0)
    return buffer

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ï¼šè‡¨åºŠæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ (å¤‰æ›´ãªã—) ---
def generate_clinical_feedback(data):
    feedback = []
    pain = data['pain']
    toe_l, toe_r = data['toe_l'], data['toe_r']
    hip_l, hip_r = data['hip_l'], data['hip_r']
    ols_l, ols_r = data['ols_l'], data['ols_r']
    frt, ffd = data['frt'], data['ffd']
    step = data['seat_step']
    
    avg_toe = (toe_l + toe_r) / 2
    if avg_toe < 15:
        level = "æ©Ÿèƒ½ä½ä¸‹" if avg_toe < 10 else "å‡ºåŠ›ä¸è¶³ãƒ»ç¡¬ã•"
        feedback.append(f"**ã€è¶³æŒ‡ï¼š{level} (å¹³å‡{avg_toe:.1f}%)ã€‘** è¶³æŒ‡ã®åŠ›ãŒåŸºæº–ä»¥ä¸‹ã§ã™ã€‚è¹´ã‚Šå‡ºã—ãŒå¼±ãã€ãƒšã‚¿ãƒšã‚¿æ­©ãã®åŸå› ã«ãªã‚Šã¾ã™ã€‚")
    
    if hip_l < 1.0 or hip_r < 1.0:
        weak_side = "å·¦" if hip_l < hip_r else "å³"
        feedback.append(f"**ã€è‚¡é–¢ç¯€ï¼šæŒ¯ã‚Šå‡ºã—ã®å¼±ã• ({weak_side}å´)ã€‘** è…¸è…°ç­‹ãŒå¼±ãã€ã¤ã¾ãšããƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚")
    
    diff_hip = abs(hip_l - hip_r)
    if diff_hip > 0.2:
        weaker = "å·¦" if hip_l < hip_r else "å³"
        stronger = "å³" if hip_l < hip_r else "å·¦"
        feedback.append(f"**ã€å·¦å³å·®ï¼š{weaker}å´ã®å¼±ã•ã¨ä»£å„Ÿã€‘** å¼±ã„{weaker}å´ã‚’ã‹ã°ã„ã€åå¯¾å´ã®{stronger}å´ã«è² æ‹…ãŒã‹ã‹ã£ã¦ã„ã¾ã™ã€‚")

    if ols_l < 20 or ols_r < 20:
        unstable = "å·¦" if ols_l < 20 else "å³"
        feedback.append(f"**ã€ãƒãƒ©ãƒ³ã‚¹ï¼šç«‹è„šæœŸã®ãµã‚‰ã¤ã ({unstable}å´)ã€‘** ç‰‡è„šç«‹ã¡æ™‚é–“ãŒçŸ­ãã€æ­©è¡Œæ™‚ã®ã‚¹ã‚¦ã‚§ã‚¤ï¼ˆæ¨ªæºã‚Œï¼‰ã«ã¤ãªãŒã‚Šã¾ã™ã€‚")

    if frt < 30:
        feedback.append(f"**ã€é‡å¿ƒç§»å‹•ï¼šå‰æ–¹ä¸å®‰ (FRT {frt}cm)ã€‘** å¾Œæ–¹é‡å¿ƒã«ãªã£ã¦ã„ã¾ã™ã€‚")

    if not feedback:
        feedback.append("âœ… **ç´ æ™´ã‚‰ã—ã„çŠ¶æ…‹ã§ã™ï¼** ç›®ç«‹ã£ãŸæ©Ÿèƒ½ä½ä¸‹ã¯è¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚")

    return feedback

# --- å‹•ç”»å‡¦ç†é–¢æ•° ---
def draw_grid_and_skeleton(image, results):
    h, w, _ = image.shape
    color_grid = (200, 200, 200)
    center_x = w // 2
    cv2.line(image, (center_x, 0), (center_x, h), (0, 255, 255), 1) 
    for x in range(0, w, w//8):
        if x != center_x: cv2.line(image, (x, 0), (x, h), color_grid, 1)
    
    if results.pose_landmarks:
        mp_drawing.draw_landmarks(
            image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
            mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2),
            mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2)
        )
    return image

def process_video_and_analyze(uploaded_file):
    if uploaded_file is None: return None, None
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(uploaded_file.read())
    cap = cv2.VideoCapture(tfile.name)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
    landmarks_history = []

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            image = draw_grid_and_skeleton(image, results)
            out.write(image)
            
            # åˆ†æç”¨ã«ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ä¿å­˜
            if results.pose_landmarks:
                landmarks_history.append(results.pose_landmarks.landmark)

    cap.release()
    out.release()
    
    # æ­©è¡ŒæŒ‡æ¨™ã®è¨ˆç®—
    metrics = analyze_gait_metrics(landmarks_history, fps)
    
    return output_path, metrics

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col1, col2 = st.columns(2)
with col1:
    st.subheader("â‘  æ­£é¢å‹•ç”»")
    file_front = st.file_uploader("Front View", type=['mp4', 'mov'], key="f")
with col2:
    st.subheader("â‘¡ å´é¢å‹•ç”» (åˆ†ææ¨å¥¨)")
    file_side = st.file_uploader("Side View", type=['mp4', 'mov'], key="s")
    st.caption("â€»æ­©è¡ŒæŒ‡æ¨™ã®ç®—å‡ºã«ã¯å´é¢å‹•ç”»ã‚’ä½¿ç”¨ã—ã¾ã™")

if st.button("ğŸš€ æ±ç”¨åˆ†æã‚’å®Ÿè¡Œ"):
    # å‡¦ç†å®Ÿè¡Œ
    path_f, metrics_f = process_video_and_analyze(file_front)
    path_s, metrics_s = process_video_and_analyze(file_side)
    
    # ãƒ¡ã‚¤ãƒ³ã®æŒ‡æ¨™ã¯ã€Œå´é¢å‹•ç”»ã€ã‹ã‚‰å–ã‚‹ï¼ˆæ­©å¹…ãŒè¦‹ã‚„ã™ã„ãŸã‚ï¼‰
    main_metrics = metrics_s if metrics_s else metrics_f
    
    st.markdown("---")
    
    # 1. çµæœè¡¨ç¤ºã‚«ãƒ©ãƒ 
    res_c1, res_c2 = st.columns([2, 1])
    
    with res_c1:
        st.subheader("ğŸ¥ è§£æå‹•ç”»")
        v_col1, v_col2 = st.columns(2)
        with v_col1:
            if path_f: st.video(path_f)
        with v_col2:
            if path_s: st.video(path_s)
            
    with res_c2:
        st.subheader("ğŸ“Š æ­©è¡ŒAIãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        if main_metrics:
            st.metric("ã‚±ã‚¤ãƒ‡ãƒ³ã‚¹ (æ­©æ•°/åˆ†)", f"{main_metrics['cadence']:.1f}", delta="æ¨™æº–: 110-120")
            st.metric("æ­©å¹…æ¯”ç‡ (æ­©å¹…/ä¸‹è…¿é•·)", f"{main_metrics['step_ratio']:.2f}", help="1.0ä»¥ä¸ŠãŒç†æƒ³çš„ã€‚ä½ã„ã¨å°åˆ»ã¿æ­©è¡Œã€‚")
            st.info(f"æ¤œå‡ºã•ã‚ŒãŸæ­©æ•°: {main_metrics['steps']}æ­© / {main_metrics['duration']:.1f}ç§’")
        else:
            st.warning("å‹•ç”»ã‹ã‚‰æ­©è¡Œãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨èº«ãŒæ˜ ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # 2. è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
    st.header("ğŸ‘¨â€âš•ï¸ AIç†å­¦ç™‚æ³•å£«ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    
    input_data = {
        'pain': pain_areas,
        'toe_l': toe_grip_l, 'toe_r': toe_grip_r,
        'hip_l': hip_flex_l, 'hip_r': hip_flex_r,
        'ols_l': one_leg_l, 'ols_r': one_leg_r,
        'frt': frt, 'ffd': ffd, 'seat_step': seat_step
    }
    
    feedbacks = generate_clinical_feedback(input_data)
    
    for msg in feedbacks:
        st.info(msg)

    # 3. æ¨å¥¨é‹å‹• & PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ‹ï¸â€â™€ï¸ æ¨å¥¨é‹å‹• & ãƒ¬ãƒãƒ¼ãƒˆ")
    rec_col1, rec_col2 = st.columns([3, 1])
    
    with rec_col1:
        if (toe_grip_l + toe_grip_r)/2 < 15:
            st.markdown("- **è¶³æŒ‡å¼·åŒ–**: ã‚¿ã‚ªãƒ«ã‚®ãƒ£ã‚¶ãƒ¼ã€è¶³æŒ‡ã˜ã‚ƒã‚“ã‘ã‚“")
        if hip_flex_l < 1.0 or hip_flex_r < 1.0:
            st.markdown("- **è…¸è…°ç­‹å¼·åŒ–**: ãƒ‹ãƒ¼ã‚¢ãƒƒãƒ—ã€å¤§è‚¡æ­©ã")
        if one_leg_l < 20 or one_leg_r < 20:
            st.markdown("- **ä¸­æ®¿ç­‹ãƒ»ãƒãƒ©ãƒ³ã‚¹**: ç‰‡è„šç«‹ã¡ä¿æŒï¼ˆ1åˆ†é–“ï¼‰")
        if frt < 30:
            st.markdown("- **å‹•çš„ãƒãƒ©ãƒ³ã‚¹**: é‡å¿ƒç§»å‹•ç·´ç¿’")
            
    with rec_col2:
        # PDFç”Ÿæˆ
        pdf_data = create_pdf(client_name, input_data, feedbacks, main_metrics)
        st.download_button(
            label="ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆPDFã‚’DL",
            data=pdf_data,
            file_name=f"{client_name}_Analysis_Report.pdf",
            mime="application/pdf"
        )
