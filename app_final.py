import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

# Phase 1-4ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from gait_event_detector import GaitEventDetector
from gait_parameter_calculator import GaitParameterCalculator
from integrated_gait_analyzer import IntegratedGaitAnalyzer

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="æ­©è¡Œåˆ†æã‚·ã‚¹ãƒ†ãƒ ", 
    page_icon="ğŸš¶",
    layout="wide"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
.big-title {
    font-size: 2.5rem;
    font-weight: bold;
    margin-bottom: 1rem;
}
.risk-box {
    padding: 1.5rem;
    border-radius: 10px;
    margin: 1rem 0;
}
.success-box {
    background-color: #d4edda;
    border-left: 5px solid #28a745;
}
.warning-box {
    background-color: #fff3cd;
    border-left: 5px solid #ffc107;
}
.error-box {
    background-color: #f8d7da;
    border-left: 5px solid #dc3545;
}
.info-box {
    background-color: #d1ecf1;
    border-left: 5px solid #17a2b8;
}
</style>
""", unsafe_allow_html=True)

# --- 2. åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®å®šç¾© ---
@st.cache_resource
def load_pose_model():
    mp_pose = mp.solutions.pose
    return mp_pose.Pose(
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5, 
        model_complexity=1,
        static_image_mode=False,
        smooth_landmarks=True
    )

def calculate_angle(a, b, c):
    """3ç‚¹ã®åº§æ¨™ã‹ã‚‰è§’åº¦ã‚’ç®—å‡º"""
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    return 360-angle if angle > 180.0 else angle

def get_line_angle(p1, p2):
    """2ç‚¹é–“ã®ãƒ™ã‚¯ãƒˆãƒ«ã®è§’åº¦"""
    return np.degrees(np.arctan2(p2[1] - p1[1], p2[0] - p1[0]))

def analyze_fall_risk(cv_value: float):
    """è»¢å€’ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡"""
    if cv_value < 3.0:
        return {
            "level": "ä½ãƒªã‚¹ã‚¯",
            "color": "success",
            "message": "æ­©è¡Œã®ä¸€å®šæ€§ãŒä¿ãŸã‚Œã¦ã„ã¾ã™ã€‚",
            "icon": "âœ…"
        }
    elif cv_value < 5.0:
        return {
            "level": "ã‚„ã‚„æ³¨æ„",
            "color": "info", 
            "message": "æ­©è¡Œã¯æ¯”è¼ƒçš„å®‰å®šã—ã¦ã„ã¾ã™ãŒã€å®šæœŸçš„ãªãƒã‚§ãƒƒã‚¯ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
            "icon": "â„¹ï¸"
        }
    elif cv_value < 10.0:
        return {
            "level": "è¦æ³¨æ„",
            "color": "warning",
            "message": "æ­©è¡Œã«ã°ã‚‰ã¤ããŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ãƒãƒ©ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
            "icon": "âš ï¸"
        }
    else:
        return {
            "level": "é«˜ãƒªã‚¹ã‚¯",
            "color": "error",
            "message": "æ­©è¡ŒãŒä¸å®‰å®šã§ã™ã€‚å°‚é–€å®¶ã¸ã®ç›¸è«‡ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
            "icon": "ğŸš¨"
        }

def analyze_spine_risk(phase_diff: float):
    """è„ŠæŸ±ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡"""
    if phase_diff >= 20.0:
        return {
            "level": "ä½ãƒªã‚¹ã‚¯",
            "color": "success",
            "message": "ä½“å¹¹ã®å”èª¿æ€§ãŒè‰¯å¥½ã§ã™ã€‚",
            "advice": "ã—ãªã‚„ã‹ãªå›æ—‹ãŒä¿ãŸã‚Œã¦ã„ã¾ã™ã€‚",
            "icon": "âœ…"
        }
    else:
        return {
            "level": "è¦æ³¨æ„",
            "color": "warning",
            "message": "èƒ¸éƒ­ã¨éª¨ç›¤ãŒåŒèª¿ã—ã™ãã¦ã„ã¾ã™ï¼ˆå‰›æ€§ã®å¢—åŠ ï¼‰ã€‚",
            "advice": "ğŸ’¡ ç†å­¦ç™‚æ³•å£«ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹: ä½“å¹¹ã®å›æ—‹ã‚’å¼•ãå‡ºã™ã‚¹ãƒˆãƒ¬ãƒƒãƒãŒæœ‰åŠ¹ã§ã™ã€‚",
            "icon": "âš ï¸"
        }

# --- 3. UIè¡¨ç¤º ---
st.markdown('<p class="big-title">ğŸš¶ æ­©è¡Œåˆ†æã‚·ã‚¹ãƒ†ãƒ </p>', unsafe_allow_html=True)
st.info("ğŸ’¡ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AIãŒè‡ªå‹•ã§æ­©è¡Œã‚’åˆ†æã—ã¾ã™")

# ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«é¸æŠ
st.subheader("ğŸ“· ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«ã‚’é¸æŠ")
camera_angle = st.radio(
    "å‹•ç”»ã®æ’®å½±è§’åº¦",
    ["ğŸ“¸ å´é¢ï¼ˆæ¨ªã‹ã‚‰ï¼‰", "ğŸ“¸ æ­£é¢ï¼ˆå‰ã‹ã‚‰ï¼‰"],
    horizontal=True
)

# å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆå‰ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹å¼ï¼‰
st.subheader("ğŸ“¹ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

if "å´é¢" in camera_angle:
    st.markdown("**åˆ†æå†…å®¹**: ç¬¬1æ­©ã®è‚¡é–¢ç¯€å±ˆæ›²è§’åº¦ã€æ­©è¡Œå‘¨æœŸ")
    uploaded_video = st.file_uploader(
        "å´é¢å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["mp4", "mov", "MP4", "MOV"],
        key="side_video"
    )
else:
    st.markdown("**åˆ†æå†…å®¹**: ä½“å¹¹ã®å·¦å³å‹•æºã€æ­©å¹…ã®å¤‰å‹•æ€§")
    uploaded_video = st.file_uploader(
        "æ­£é¢å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        type=["mp4", "mov", "MP4", "MOV"],
        key="front_video"
    )

# è§£æå¤‰æ•°ã®åˆæœŸåŒ–
max_flexion_angle = 0.0
calculated_cv = 0.0
calculated_phase = 0.0

# --- 4. è§£æå®Ÿè¡Œ ---
if uploaded_video is not None:
    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
    file_size_mb = uploaded_video.size / (1024 * 1024)
    st.success(f"âœ… {uploaded_video.name} ({file_size_mb:.1f}MB) ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    
    # å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    with st.expander("ğŸ¬ å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        st.video(uploaded_video)
    
    if st.button("âœ¨ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è§£æã‚’é–‹å§‹", type="primary", use_container_width=True):
        with st.spinner("ğŸ”„ è§£æä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„"):
            try:
                # MediaPipeæº–å‚™
                pose_engine = load_pose_model()
                mp_pose = mp.solutions.pose
                mp_drawing = mp.solutions.drawing_utils
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                file_extension = uploaded_video.name.split('.')[-1].lower()
                if file_extension == 'mov':
                    file_extension = 'mp4'
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as tfile:
                    tfile.write(uploaded_video.read())
                    temp_path = tfile.name
                
                # å‹•ç”»ã‚’é–‹ã
                cap = cv2.VideoCapture(temp_path)
                
                if not cap.isOpened():
                    st.error("âŒ å‹•ç”»ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
                else:
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    progress_bar = st.progress(0)
                    st.info(f"ğŸ“Š ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
                    
                    if "å´é¢" in camera_angle:
                        # --- å´é¢è§£æ ---
                        best_frame_flex = None
                        frame_count = 0
                        
                        while cap.isOpened():
                            ret, frame = cap.read()
                            if not ret:
                                break
                            
                            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                            results = pose_engine.process(image)
                            
                            if results.pose_landmarks:
                                lm = results.pose_landmarks.landmark
                                s = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, 
                                     lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                                h = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, 
                                     lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                                k = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, 
                                     lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                                
                                current_angle = calculate_angle(s, h, k)
                                flex_val = np.abs(180 - current_angle)
                                
                                if flex_val > max_flexion_angle:
                                    max_flexion_angle = flex_val
                                    best_frame_flex = image.copy()
                                    mp_drawing.draw_landmarks(
                                        best_frame_flex, 
                                        results.pose_landmarks, 
                                        mp_pose.POSE_CONNECTIONS
                                    )
                            
                            frame_count += 1
                            if frame_count % 10 == 0:
                                progress_bar.progress(min(frame_count / total_frames, 1.0))
                        
                        cap.release()
                        progress_bar.progress(1.0)
                        
                        # çµæœè¡¨ç¤º
                        st.success("âœ… è§£æå®Œäº†ï¼")
                        st.markdown("---")
                        
                        st.subheader("ğŸ“Š å´é¢åˆ†æçµæœ")
                        
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            st.metric("ç¬¬1æ­©ï¼šæœ€å¤§è‚¡é–¢ç¯€å±ˆæ›²è§’åº¦", f"{max_flexion_angle:.1f}Â°")
                            st.markdown("ğŸ‘‰ **Sakane(2025)** åŸºæº–ã«åŸºã¥ãã€æŒ¯ã‚Šå‡ºã—ã®å¼·ã•ã‚’è©•ä¾¡")
                            
                            if max_flexion_angle < 30:
                                st.warning("âš ï¸ è‚¡é–¢ç¯€ã®æŒ¯ã‚Šå‡ºã—ãŒå°ã•ã‚ã§ã™")
                            elif max_flexion_angle >= 50:
                                st.success("âœ… è‰¯å¥½ãªæŒ¯ã‚Šå‡ºã—")
                        
                        with col2:
                            if best_frame_flex is not None:
                                st.image(
                                    best_frame_flex, 
                                    caption="AIãŒç‰¹å®šã—ãŸæœ€å¤§å±ˆæ›²ã®ç¬é–“",
                                    use_container_width=True
                                )
                    
                    else:
                        # --- æ­£é¢è§£æ ---
                        step_widths, phase_diffs = [], []
                        frame_count = 0
                        
                        while cap.isOpened():
                            ret, frame = cap.read()
                            if not ret:
                                break
                            
                            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                            results = pose_engine.process(image)
                            
                            if results.pose_landmarks:
                                lm = results.pose_landmarks.landmark
                                
                                # è‚©ã¨è…°ã®å‚¾ã
                                ls = [lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x, 
                                      lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y]
                                rs = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, 
                                      lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]
                                lh = [lm[mp_pose.PoseLandmark.LEFT_HIP].x, 
                                      lm[mp_pose.PoseLandmark.LEFT_HIP].y]
                                rh = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, 
                                      lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                                
                                phase_diffs.append(
                                    abs(get_line_angle(ls, rs) - get_line_angle(lh, rh))
                                )
                                
                                # ã‚¹ãƒ†ãƒƒãƒ—å¹…
                                step_widths.append(
                                    abs(lm[mp_pose.PoseLandmark.LEFT_HEEL].x - 
                                        lm[mp_pose.PoseLandmark.RIGHT_HEEL].x)
                                )
                            
                            frame_count += 1
                            if frame_count % 10 == 0:
                                progress_bar.progress(min(frame_count / total_frames, 1.0))
                        
                        cap.release()
                        progress_bar.progress(1.0)
                        
                        # CVå€¤è¨ˆç®—
                        if step_widths and np.mean(step_widths) != 0:
                            calculated_cv = (np.std(step_widths) / np.mean(step_widths)) * 100
                        
                        calculated_phase = np.mean(phase_diffs) if phase_diffs else 0
                        
                        # çµæœè¡¨ç¤º
                        st.success("âœ… è§£æå®Œäº†ï¼")
                        st.markdown("---")
                        
                        st.subheader("ğŸ“Š æ­£é¢åˆ†æçµæœ")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric(
                                "æ­©å¹…CVå€¤ï¼ˆå¤‰å‹•æ€§ï¼‰", 
                                f"{calculated_cv:.1f}%",
                                delta=f"{calculated_cv-21.7:.1f}% vs é–¾å€¤",
                                delta_color="inverse"
                            )
                        with col2:
                            st.metric(
                                "è„ŠæŸ±å”èª¿æ€§(ä½ç›¸å·®)", 
                                f"{calculated_phase:.1f}Â°",
                                delta=f"{calculated_phase-20:.1f}Â° vs é–¾å€¤"
                            )
                        
                        # ç·åˆåˆ¤å®š
                        st.markdown("---")
                        st.header("ğŸ“‹ ç·åˆãƒªã‚¹ã‚¯åˆ¤å®š")
                        
                        r1, r2 = st.columns(2)
                        
                        with r1:
                            st.subheader("ğŸš¨ è»¢å€’ãƒªã‚¹ã‚¯è©•ä¾¡")
                            fall_risk = analyze_fall_risk(calculated_cv)
                            
                            risk_class = f"{fall_risk['color']}-box"
                            st.markdown(f"""
                            <div class="risk-box {risk_class}">
                                <h3>{fall_risk['icon']} ã€{fall_risk['level']}ã€‘</h3>
                                <p>{fall_risk['message']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with r2:
                            st.subheader("ğŸ¦´ è„ŠæŸ±ãƒ»è…°ç—›ãƒªã‚¹ã‚¯è©•ä¾¡")
                            spine_risk = analyze_spine_risk(calculated_phase)
                            
                            risk_class = f"{spine_risk['color']}-box"
                            st.markdown(f"""
                            <div class="risk-box {risk_class}">
                                <h3>{spine_risk['icon']} ã€{spine_risk['level']}ã€‘</h3>
                                <p>{spine_risk['message']}</p>
                                <p><strong>{spine_risk['advice']}</strong></p>
                            </div>
                            """, unsafe_allow_html=True)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.unlink(temp_path)
            
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                import traceback
                with st.expander("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                    st.code(traceback.format_exc())

# ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ ¹æ‹ 
with st.expander("ğŸ“š ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ ¹æ‹ ï¼ˆPTç”¨ï¼‰"):
    st.markdown("""
    ### è»¢å€’ãƒªã‚¹ã‚¯è©•ä¾¡ã®æ ¹æ‹ 
    - **å¤‰å‹•ä¿‚æ•° (CV) < 3%**: æ­£å¸¸ãªæ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
    - **CV 3-5%**: è»½åº¦ã®ä¸å®‰å®šæ€§
    - **CV 5-10%**: ä¸­ç­‰åº¦ã®ä¸å®‰å®šæ€§
    - **CV > 10%**: é«˜åº¦ãªä¸å®‰å®šæ€§ï¼ˆè¦ä»‹å…¥ï¼‰
    
    **å‚è€ƒæ–‡çŒ®**: 
    - Sakane (2025): ç¬¬1æ­©ã®è‚¡é–¢ç¯€å±ˆæ›²ã¨è»¢å€’ãƒªã‚¹ã‚¯
    - Park (2025): ã‚¹ãƒ†ãƒƒãƒ—å¹…CVå€¤ã®ã‚«ãƒƒãƒˆã‚ªãƒ• 21.7%
    
    ### è„ŠæŸ±ãƒªã‚¹ã‚¯è©•ä¾¡ã®æ ¹æ‹ 
    - ç›¸å¯¾ä½ç›¸å·® **20åº¦æœªæº€** ã‚’å‰›æ€§å¢—åŠ ã®æŒ‡æ¨™ã¨ã™ã‚‹
    - ä½“å¹¹ã®å”èª¿æ€§ã¨è…°ç—›ã®é–¢é€£
    
    **å‚è€ƒæ–‡çŒ®**:
    - Lamoth et al. (2002): Pelvis-thorax coordination
    - Smith/Xu: ä½“å¹¹ã®åŒèª¿ã¨è…°ç—›ãƒªã‚¹ã‚¯
    """)

if __name__ == "__main__":
    pass
